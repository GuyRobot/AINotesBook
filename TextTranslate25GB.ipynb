{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TextTranslate25GB","provenance":[{"file_id":"1oGXlUH5nZpY0DtvyD3aNF9BJ8PBZ7xvr","timestamp":1615606457247},{"file_id":"1twNetFPIoMKNy13z_URcoMnz3lM2UBEM","timestamp":1602893130525}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60NlBzUY0p4v","executionInfo":{"status":"ok","timestamp":1615871498426,"user_tz":-420,"elapsed":62098,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"106c68e3-73e8-4a19-87f1-da75f1332189"},"source":["from google.colab import drive\n","drive.mount(\"/content/data\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"FLVd7dMX0Juy"},"source":["import os\n","import numpy as np\n","import unicodedata\n","import tensorflow as tf\n","import re\n","import io\n","import time\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75tqDrq10Ju3"},"source":["path_data_file = \"/content/data/MyDrive/data/rus-eng/rus.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"WSaFZmpj0Ju4","executionInfo":{"status":"ok","timestamp":1615871500589,"user_tz":-420,"elapsed":64243,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"0bc5fb80-9400-42a6-d566-80ed1cf76b5d"},"source":["def unicode_to_ascii(w):\n","    return ''.join(unicodedata.normalize(\"NFD\", c) for c in w if unicodedata.category(c) != 'Mn')\n","\n","word = \"Оно там?\"\n","unicode_to_ascii(word)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Оно там?'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"LAnnLl-M0Ju5","executionInfo":{"status":"ok","timestamp":1615871500590,"user_tz":-420,"elapsed":64231,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"2753a90c-696e-4317-cd4c-c9fa870b24ef"},"source":["def preprocess_word(w):\n","    w = unicode_to_ascii(w)\n","\n","    w = re.sub(r\"([.!?,])\", r\" \\1\", w)\n","    w = re.sub(r'[\" ]', \" \", w)\n","\n","    w = w.strip()\n","    return \"<start> %s <end>\" % w\n","\n","preprocess_word(word)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<start> Оно там ? <end>'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkQaxG1S0Ju5","executionInfo":{"status":"ok","timestamp":1615871504463,"user_tz":-420,"elapsed":68090,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"1766ed1a-cd42-4934-b835-2655719b48ca"},"source":["def create_dataset(path, num_instance):\n","    lines = io.open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n","    return zip(*[[preprocess_word(w) for w in line.split(\"\\t\")[:2]] for line in lines[:num_instance]])\n","\n","a, b = create_dataset(path_data_file, 3)\n","a, b"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(('<start> Go . <end>', '<start> Go . <end>', '<start> Go . <end>'),\n"," ('<start> Марш ! <end>', '<start> Иди . <end>', '<start> Идите . <end>'))"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"kjMePHWa0Ju6"},"source":["def tokenize(texts):\n","    \"\"\"\n","\n","    :param texts: the text to tokenize\n","    :return: the tensors and tokenizer of the texts\n","    \"\"\"\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","    tokenizer.fit_on_texts(texts)\n","\n","    tensor = tokenizer.texts_to_sequences(texts)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\n","\n","    return tensor, tokenizer\n","\n","\n","def load_dataset(path, num_instance):\n","    tar, inp = create_dataset(path, num_instance)\n","\n","    tar_tensor, tar_tokenizer = tokenize(tar)\n","    inp_tensor, inp_tokenizer = tokenize(inp)\n","\n","    return tar_tensor, inp_tensor, tar_tokenizer, inp_tokenizer\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9ogCsc30Ju6","executionInfo":{"status":"ok","timestamp":1615871513235,"user_tz":-420,"elapsed":76853,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"58f5f16f-d0eb-4df6-816a-9ca84fb9bae2"},"source":["NUM_EXAMPLES = 150000\n","\n","tar_tensor, inp_tensor, tar_tokenizer, inp_tokenizer = load_dataset(path_data_file, NUM_EXAMPLES)\n","\n","max_len_tar = tar_tensor.shape[1]\n","max_len_inp = inp_tensor.shape[1]\n","\n","max_len_tar, max_len_inp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12, 15)"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqZbiAjg0Ju6","executionInfo":{"status":"ok","timestamp":1615871513236,"user_tz":-420,"elapsed":76847,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"9800fbea-c304-43f4-b6d0-4fb7e02d95fc"},"source":["inp_tensor_train, inp_tensor_val, tar_tensor_train, tar_tensor_val = train_test_split(inp_tensor, tar_tensor)\n","\n","len(inp_tensor_train), len(inp_tensor_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(112500, 37500)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cyv7lBVQ0Ju7","executionInfo":{"status":"ok","timestamp":1615871513238,"user_tz":-420,"elapsed":76843,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"dda3f045-c566-494f-e994-e3e538128d2c"},"source":["def print_convert(tokenizer, tensor):\n","    for t in tensor:\n","        if t != 0:\n","            print(\"%d\\t--->\\t%s\" % (t, tokenizer.index_word[t]))\n","\n","print_convert(inp_tokenizer, inp_tensor_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\t--->\t<start>\n","10\t--->\tты\n","523\t--->\tделаешь\n","17\t--->\tменя\n","150\t--->\tтакой\n","989\t--->\tсчастливой\n","3\t--->\t.\n","2\t--->\t<end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXfjRzOt0Ju7","executionInfo":{"status":"ok","timestamp":1615871518498,"user_tz":-420,"elapsed":82097,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"597bfa1f-fac1-4c26-af2b-c1ff0aad057f"},"source":["BUFFER_SIZE = 10000\n","BATCH_SIZE = 64\n","\n","dataset = tf.data.Dataset.from_tensor_slices((inp_tensor_train, tar_tensor_train))\n","dataset = dataset.shuffle(BUFFER_SIZE).cache().batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((64, 15), (64, 12)), types: (tf.int32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"VtpFWiDb0Ju7"},"source":["EMBEDDING_DIM = 256\n","ENC_UNITS = 1024\n","DEC_UNITS = 1024\n","\n","vocab_inp_size = len(inp_tokenizer.word_index) + 1\n","vocab_tar_size = len(tar_tokenizer.word_index) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5c4PNmP0Ju8","executionInfo":{"status":"ok","timestamp":1615871518499,"user_tz":-420,"elapsed":82091,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"6fb187b6-1663-487e-ae3d-a02819a56d16"},"source":["for exam_inp, exam_tar in dataset.take(1):\n","    print(exam_inp.shape, exam_tar.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(64, 15) (64, 12)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aR2RZrnZ0Ju8","executionInfo":{"status":"ok","timestamp":1615871545709,"user_tz":-420,"elapsed":109296,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"3964478e-e126-4bc9-9576-53bebb9b10ac"},"source":["class Encoder(tf.keras.Model):\n","    def get_config(self):\n","        pass\n","    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n","        self.batch_size = batch_size\n","        self.encoder_units = encoder_units\n","        super(Encoder, self).__init__()\n","        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.gru = tf.keras.layers.GRU(encoder_units, return_sequences=True, return_state=True,\n","                                       recurrent_initializer=\"glorot_uniform\")\n","\n","    def call(self, x, hidden, *args):\n","        x = self.embedding(x)\n","        output, state = self.gru(x, initial_state=hidden)\n","        return output, state\n","\n","    def initialize_hidden(self):\n","        return tf.zeros((self.batch_size, self.encoder_units))\n","\n","\n","exam_inp, exam_tar = next(iter(dataset))\n","encoder_test = Encoder(vocab_inp_size, EMBEDDING_DIM, ENC_UNITS, batch_size=BATCH_SIZE)\n","\n","init_hidden = encoder_test.initialize_hidden()\n","sample_output, sample_hidden = encoder_test(exam_inp, init_hidden)\n","\n","\"Encoder Output Shape: \", sample_output.shape, \"Encoder Hidden shape: \", sample_hidden.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Encoder Output Shape: ',\n"," TensorShape([64, 15, 1024]),\n"," 'Encoder Hidden shape: ',\n"," TensorShape([64, 1024]))"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FS7wiM7F0Ju8","executionInfo":{"status":"ok","timestamp":1615871549030,"user_tz":-420,"elapsed":112610,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"4d9411ba-9fe9-4986-8b69-6e445314a2bb"},"source":["class BahdanauAttention(tf.keras.Model):\n","    def __init__(self, fc_units):\n","        super(BahdanauAttention, self).__init__()\n","        self.fc1 = tf.keras.layers.Dense(fc_units)\n","        self.fc2 = tf.keras.layers.Dense(fc_units)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    def call(self, query, values, *args):\n","        \"\"\"\n","\n","        :param query: The hidden from encoder (batch_size, enc_hidden)\n","        :param values: encoder output (batch_size, seq_len, enc_hidden)\n","        :param args:\n","        :return:\n","        \"\"\"\n","        # query hidden state shape == (batch_size, hidden size)\n","        # query_with_time_axis shape == (batch_size, 1, hidden size)\n","        # values shape == (batch_size, max_len, hidden size)\n","        # expand dim to broadcast addition along the time axis to calculate the score\n","        query_time_with_axis = tf.expand_dims(query, axis=1)\n","        # fc2 --> (batch_size, 1, units)\n","        # fc1 --> (batch_size, max_len, units)\n","        # fc1 + fc2 --> (batch_size, max_len, units)\n","        # V --> (batch_size, max_len, 1) (score shape)\n","        score = self.V(tf.tanh(self.fc2(query_time_with_axis) + self.fc1(values)))\n","        # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","        # Point wise element multi (not dot product)\n","        context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n","        # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","\n","        return context_vector, attention_weights\n","\n","    # def call(self, inputs, training=None, mask=None):\n","    #     encoder_out, hidden = inputs\n","    #     score = self.V(tf.tanh(self.fc2(encoder_out) + self.fc1(hidden)))\n","    #     # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","    #     attention_weights = tf.nn.softmax(score, axis=1)\n","    #     context_vector = tf.reduce_sum(attention_weights * encoder_out, axis=1)\n","    #     # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","    #\n","    #     return context_vector, attention_weights\n","\n","attention = BahdanauAttention(10)\n","attention_context, attention_weights = attention(sample_hidden, sample_output)\n","\n","\"Attention context shape: \", attention_context.shape, \"attention weights shape: \", attention_weights.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Attention context shape: ',\n"," TensorShape([64, 1024]),\n"," 'attention weights shape: ',\n"," TensorShape([64, 15, 1]))"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOXqDioW0Ju9","executionInfo":{"status":"ok","timestamp":1615871549031,"user_tz":-420,"elapsed":112604,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"fca7c092-1fae-4b59-e08b-77c768ac5cef"},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units):\n","        super(Decoder, self).__init__()\n","        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.gru = tf.keras.layers.GRU(units=dec_units, return_state=True, return_sequences=True,\n","                                       recurrent_initializer=\"glorot_uniform\")\n","\n","        self.final_fc = tf.keras.layers.Dense(vocab_size)\n","\n","        self.attention = BahdanauAttention(dec_units)\n","\n","    def call(self, x, hidden, enc_output):\n","        \"\"\"\n","        :param x: inputs\n","        :param hidden: hidden from encoder\n","        :param enc_output: output of encoder\n","        :return:\n","        \"\"\"\n","\n","        # (batch_size, hidden_units), (batch_size, seq_len, hidden_units)\n","        # embedded (batch_size, ..., embedding_dim)\n","        # concat (batch_size, ..., embedding_dim + units)\n","        # gru --> out (batch_size, ..., units), state (batch_size, units)\n","        # reshape --> merge batch_size and ... --> (batch_size, units)\n","        # fc --> (batch_size, vocab_size)\n","        context_vector, context_weights = self.attention(hidden, enc_output)\n","        x = self.embedding(x)\n","        x = tf.concat([x, tf.expand_dims(context_vector, axis=1)], axis=-1)\n","\n","        out, state = self.gru(x)\n","\n","        out = tf.reshape(out, shape=(-1, out.shape[2]))\n","\n","        x = self.final_fc(out)\n","\n","        return x, state, attention_weights\n","\n","\n","decoder = Decoder(vocab_tar_size, embedding_dim=EMBEDDING_DIM, dec_units=DEC_UNITS)\n","\n","sample_decode_output, _, _ = decoder(tf.random.uniform(shape=(BATCH_SIZE, 1)), sample_hidden, sample_output)\n","\n","sample_decode_output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 8952])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"RHyvfgwf0Ju-"},"source":["optimizer = tf.keras.optimizers.Adam()\n","sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_func(real, pred):\n","    # Mask for target (0 is mask, 1 is real target)\n","    mask = tf.math.logical_not(tf.equal(real, 0))\n","    loss = sparse_loss(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    # ignore for mask loss\n","    loss *= mask\n","\n","    return tf.reduce_mean(loss)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYUl3V5p0Ju-","executionInfo":{"status":"ok","timestamp":1615871549548,"user_tz":-420,"elapsed":113114,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"f3298cb3-679b-441a-e080-33c5007b085d"},"source":["encoder = Encoder(vocab_size=vocab_inp_size, embedding_dim=EMBEDDING_DIM, encoder_units=ENC_UNITS, batch_size=BATCH_SIZE)\n","decoder = Decoder(vocab_size=vocab_tar_size, embedding_dim=EMBEDDING_DIM, dec_units=DEC_UNITS)\n","\n","checkpoint_dir = \"/content/data/MyDrive/checkpoints/text_translate\"\n","checkpoint = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer, step=tf.Variable(1))\n","manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=1)\n","# checkpoint.restore(manager.latest_checkpoint)\n","# if manager.latest_checkpoint:\n","    # print(\"Restored from {}\".format(manager.latest_checkpoint))\n","# else:\n","    # print(\"Initializing from scratch.\")\n","\n","checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.Checkpoint at 0x7f182b881f90>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"06rDLtN_0Ju-"},"source":["@tf.function\n","def train_step(inp, tar, enc_hidden):\n","    \"\"\"\n","    Pass the input through the encoder which return encoder output and the encoder hidden state.\n","    The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n","    The decoder returns the predictions and the decoder hidden state.\n","    The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n","    Use teacher forcing to decide the next input to the decoder.\n","    Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n","    The final step is to calculate the gradients and apply it to the optimizer and backpropagate\n","    :param inp:\n","    :param tar:\n","    :param enc_hidden:\n","    :return:\n","    \"\"\"\n","    loss = 0.0\n","\n","    with tf.GradientTape() as g:\n","\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","        dec_input = tf.expand_dims([tar_tokenizer.word_index['<start>']] * BATCH_SIZE, axis=1)\n","        dec_hidden = enc_hidden\n","        for t in range(1, tar.shape[1]):\n","            predictions, state, _ = decoder(dec_input, dec_hidden, enc_output)\n","            loss += loss_func(tar[:, t], predictions)\n","\n","            dec_input = tf.expand_dims(tar[:, t], axis=1)\n","\n","    batch_loss = (loss / int(tar.shape[1]))\n","\n","    train_variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","    gradients = g.gradient(loss, train_variables)\n","\n","    optimizer.apply_gradients(zip(gradients, train_variables))\n","\n","    return batch_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLf2pmJq0Ju_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1615872075145,"user_tz":-420,"elapsed":638708,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"dde319d8-d175-4f68-a1fa-955688290e07"},"source":["EPOCHS = 20\n","steps_per_epoch = len(inp_tensor_train) // BATCH_SIZE\n","\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    enc_hidden = encoder.initialize_hidden()\n","    start = time.time()\n","    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n","        loss = train_step(inp, tar, enc_hidden)\n","        total_loss += loss\n","\n","        if batch % 100 == 0:\n","            print('Epoch %d Batch %d Loss %.4f' % (epoch + 1, batch, loss.numpy()))\n","    \n","    \n","    # checkpoint.step.assign_add(1)\n","    # manager.save()\n","    # checkpoint.save(file_prefix=checkpoint_prefix)\n","\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.7514\n","Epoch 1 Batch 100 Loss 2.2475\n","Epoch 1 Batch 200 Loss 1.9592\n","Epoch 1 Batch 300 Loss 1.8101\n","Epoch 1 Batch 400 Loss 1.7925\n","Epoch 1 Batch 500 Loss 1.5098\n","Epoch 1 Batch 600 Loss 1.4591\n","Epoch 1 Batch 700 Loss 1.4134\n","Epoch 1 Batch 800 Loss 1.3025\n","Epoch 1 Batch 900 Loss 1.2295\n","Epoch 1 Batch 1000 Loss 1.2663\n","Epoch 1 Batch 1100 Loss 1.1056\n","Epoch 1 Batch 1200 Loss 0.9932\n","Epoch 1 Batch 1300 Loss 1.0235\n","Epoch 1 Batch 1400 Loss 0.9037\n","Epoch 1 Batch 1500 Loss 0.9304\n","Epoch 1 Batch 1600 Loss 0.8729\n","Epoch 1 Batch 1700 Loss 0.6965\n","Epoch 1 Loss 1.3523\n","Time taken for 1 epoch 158.07966089248657 sec\n","\n","Epoch 2 Batch 0 Loss 0.7573\n","Epoch 2 Batch 100 Loss 0.8084\n","Epoch 2 Batch 200 Loss 0.7277\n","Epoch 2 Batch 300 Loss 0.6855\n","Epoch 2 Batch 400 Loss 0.8240\n","Epoch 2 Batch 500 Loss 0.5633\n","Epoch 2 Batch 600 Loss 0.5963\n","Epoch 2 Batch 700 Loss 0.5648\n","Epoch 2 Batch 800 Loss 0.5593\n","Epoch 2 Batch 900 Loss 0.5656\n","Epoch 2 Batch 1000 Loss 0.5720\n","Epoch 2 Batch 1100 Loss 0.5546\n","Epoch 2 Batch 1200 Loss 0.4293\n","Epoch 2 Batch 1300 Loss 0.4884\n","Epoch 2 Batch 1400 Loss 0.4317\n","Epoch 2 Batch 1500 Loss 0.3973\n","Epoch 2 Batch 1600 Loss 0.4183\n","Epoch 2 Batch 1700 Loss 0.3070\n","Epoch 2 Loss 0.5480\n","Time taken for 1 epoch 149.4822962284088 sec\n","\n","Epoch 3 Batch 0 Loss 0.3384\n","Epoch 3 Batch 100 Loss 0.3923\n","Epoch 3 Batch 200 Loss 0.3807\n","Epoch 3 Batch 300 Loss 0.3451\n","Epoch 3 Batch 400 Loss 0.4154\n","Epoch 3 Batch 500 Loss 0.2955\n","Epoch 3 Batch 600 Loss 0.3247\n","Epoch 3 Batch 700 Loss 0.3001\n","Epoch 3 Batch 800 Loss 0.2852\n","Epoch 3 Batch 900 Loss 0.2967\n","Epoch 3 Batch 1000 Loss 0.3363\n","Epoch 3 Batch 1100 Loss 0.3135\n","Epoch 3 Batch 1200 Loss 0.2628\n","Epoch 3 Batch 1300 Loss 0.2794\n","Epoch 3 Batch 1400 Loss 0.2623\n","Epoch 3 Batch 1500 Loss 0.2159\n","Epoch 3 Batch 1600 Loss 0.2339\n","Epoch 3 Batch 1700 Loss 0.1810\n","Epoch 3 Loss 0.2943\n","Time taken for 1 epoch 149.71012234687805 sec\n","\n","Epoch 4 Batch 0 Loss 0.2001\n","Epoch 4 Batch 100 Loss 0.2287\n","Epoch 4 Batch 200 Loss 0.2508\n","Epoch 4 Batch 300 Loss 0.2240\n","Epoch 4 Batch 400 Loss 0.2120\n","Epoch 4 Batch 500 Loss 0.2237\n","Epoch 4 Batch 600 Loss 0.1891\n","Epoch 4 Batch 700 Loss 0.1744\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-70f509fdad3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"F4Vsvy-BQ5sM"},"source":["# Translate\n","# The input to the decoder at each time step is its previous predictions along with the hidden state and\n","# the decoder output\n","# Stop prediction when reach end token and store the attention weights for every time step\n","# The encoder output is calculated only once for one input\n","\n","def evaluate(sentence):\n","    sentence = sentence.lower()\n","    attention_plot = np.zeros((max_len_tar, max_len_inp))\n","\n","    sentence = preprocess_word(sentence)\n","\n","    inputs = [inp_tokenizer.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_inp, padding='post')\n","\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = ''\n","\n","    hidden = [tf.zeros((1, DEC_UNITS))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([tar_tokenizer.word_index['<start>']], 0)\n","\n","    for t in range(max_len_tar):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n","\n","        # Storing the attention weights to plot later on\n","        attention_weights = tf.reshape(attention_weights, shape=(-1, ))\n","        # attention_plot[t] = attention_weights.numpy()\n","\n","        prediction_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += tar_tokenizer.index_word[prediction_id] + ' '\n","\n","        if tar_tokenizer.index_word[prediction_id] == '<end>':\n","            return result, sentence, attention_plot\n","\n","        # Feed back into the model the predicted id\n","        dec_input = tf.expand_dims([prediction_id], 0)\n","\n","    return result, sentence, attention_plot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hW7jb3cDRbd6"},"source":["def translate(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","\n","    print('Input: %s' % sentence)\n","    print(\"Predicted translation: {}\".format(result))\n","\n","    # attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    # plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqWWEWDlSCGV","executionInfo":{"status":"ok","timestamp":1615872191856,"user_tz":-420,"elapsed":1531,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"e78b5f74-0833-4dce-d442-ff79e1944838"},"source":["# translate(u'Go')\n","# Позвони Тому.\n","# Вот это да\n","# inp_tokenizer.word_index['Тому']\n","# inp_tokenizer.word_index[u'тому']\n","translate(u'Я совсем о ней забыл.')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: <start> я совсем о ней забыл . <end>\n","Predicted translation: i forgot all . <end> \n"],"name":"stdout"}]}]}