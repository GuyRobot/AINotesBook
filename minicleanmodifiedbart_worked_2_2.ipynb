{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4fdd3390545a466882280848d76d8d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91c20d96093b4c668c1be20f2a808de8",
              "IPY_MODEL_c98284291ea0414b998543459029bf3a",
              "IPY_MODEL_5ece372fe5624636bd19486fd2bc8930"
            ],
            "layout": "IPY_MODEL_b5c35e13e5fa4245beacab01d189c25d"
          }
        },
        "91c20d96093b4c668c1be20f2a808de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7832e72b4c7e4403b7d29def6b3d0daf",
            "placeholder": "​",
            "style": "IPY_MODEL_1b82787bcb5c482684162c52c1f32941",
            "value": "Downloading builder script: 100%"
          }
        },
        "c98284291ea0414b998543459029bf3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10bddf5309ec498dbfe0add08e796520",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_305c22ea194f4ac49d470bb2a419e616",
            "value": 6270
          }
        },
        "5ece372fe5624636bd19486fd2bc8930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70d2d11a719c4685a61ba585ab76d51f",
            "placeholder": "​",
            "style": "IPY_MODEL_4cc5dbae9d9a432689c81dcbae6c5762",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 416kB/s]"
          }
        },
        "b5c35e13e5fa4245beacab01d189c25d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7832e72b4c7e4403b7d29def6b3d0daf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b82787bcb5c482684162c52c1f32941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10bddf5309ec498dbfe0add08e796520": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305c22ea194f4ac49d470bb2a419e616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70d2d11a719c4685a61ba585ab76d51f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc5dbae9d9a432689c81dcbae6c5762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79ae3e641e3947e8a03dbc4e20c9c510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_005a505a5a4b452c95e2eb2df8e5d429",
              "IPY_MODEL_f61abb9c21a64e44b291da97ac6adba5",
              "IPY_MODEL_43675ab8c69a488dabebdfe6bfb768ec"
            ],
            "layout": "IPY_MODEL_998ee281a4fa4217a6e4515059860ad2"
          }
        },
        "005a505a5a4b452c95e2eb2df8e5d429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774eedabc0ff4da6b2cf883c9a7b4de1",
            "placeholder": "​",
            "style": "IPY_MODEL_2a05fcbb53e74330a80cfcae51a9e32b",
            "value": "config.json: 100%"
          }
        },
        "f61abb9c21a64e44b291da97ac6adba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac80e9738f9e447ab15e2c7f0827e08c",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5854fbc564ab432c91076abb466c1184",
            "value": 1716
          }
        },
        "43675ab8c69a488dabebdfe6bfb768ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a11765905649f48a8f3287cf509029",
            "placeholder": "​",
            "style": "IPY_MODEL_00e013636189445caf410894491245f4",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 109kB/s]"
          }
        },
        "998ee281a4fa4217a6e4515059860ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "774eedabc0ff4da6b2cf883c9a7b4de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a05fcbb53e74330a80cfcae51a9e32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac80e9738f9e447ab15e2c7f0827e08c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5854fbc564ab432c91076abb466c1184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96a11765905649f48a8f3287cf509029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e013636189445caf410894491245f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6da50dd8f64a428098a740ed18272777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92e7b78e94b947ed9e0e9ab22b9007bd",
              "IPY_MODEL_ebd4e1b6e0da41719d79046b60f2e6ba",
              "IPY_MODEL_7cc399ccc2d44d54bfa611ca39558825"
            ],
            "layout": "IPY_MODEL_3e0ea1386fea40d98e20b87a750911a7"
          }
        },
        "92e7b78e94b947ed9e0e9ab22b9007bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75c96c8853874a1ca0fa5bf3467f53d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3f90207c70ed440f8d2f536f98775b8f",
            "value": "vocab.json: 100%"
          }
        },
        "ebd4e1b6e0da41719d79046b60f2e6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ff8532a83440129760ab91c0d987ed",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c48509f0b7b425180bc06be777bd144",
            "value": 898823
          }
        },
        "7cc399ccc2d44d54bfa611ca39558825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f71d77e35b864b9a88bb98dbc9ae2aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_79522cd5df524bada6436f54235623a5",
            "value": " 899k/899k [00:00&lt;00:00, 6.62MB/s]"
          }
        },
        "3e0ea1386fea40d98e20b87a750911a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c96c8853874a1ca0fa5bf3467f53d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f90207c70ed440f8d2f536f98775b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ff8532a83440129760ab91c0d987ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c48509f0b7b425180bc06be777bd144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f71d77e35b864b9a88bb98dbc9ae2aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79522cd5df524bada6436f54235623a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c66250fdaa74d4e9b1a0901d832bb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a3b732fdec145f78de08802fb1fdf21",
              "IPY_MODEL_c53bf696aeaf413c9b0bbbafc6b234d0",
              "IPY_MODEL_579885f8be8b4559b4093c954ae7e93e"
            ],
            "layout": "IPY_MODEL_46e249d74fb64dfa8a3ca8e43396742c"
          }
        },
        "4a3b732fdec145f78de08802fb1fdf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff4f588e837d4910a41ebd303f8a5ad7",
            "placeholder": "​",
            "style": "IPY_MODEL_243f78c2655245f086481b6f5263b5a9",
            "value": "merges.txt: 100%"
          }
        },
        "c53bf696aeaf413c9b0bbbafc6b234d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb52dd3687a4fe3994e75b0a5b23b11",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f384adee5cb41e49aec08fb2b428c30",
            "value": 456318
          }
        },
        "579885f8be8b4559b4093c954ae7e93e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2af265a792254592bd7f2f4f2a63704e",
            "placeholder": "​",
            "style": "IPY_MODEL_a9bddf41a6424a01b0dfc65732fcbb3e",
            "value": " 456k/456k [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "46e249d74fb64dfa8a3ca8e43396742c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4f588e837d4910a41ebd303f8a5ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243f78c2655245f086481b6f5263b5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb52dd3687a4fe3994e75b0a5b23b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f384adee5cb41e49aec08fb2b428c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2af265a792254592bd7f2f4f2a63704e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bddf41a6424a01b0dfc65732fcbb3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c41716bf8a54b33bdc3fbdf09c197d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776ae0d5e3ba4ff9a3b086149294ce18",
              "IPY_MODEL_8d0775572de441c38753a024fbd43663",
              "IPY_MODEL_d74945c034894c33bbdd2f8e96903930"
            ],
            "layout": "IPY_MODEL_95b31e6ce8df4f1bb5ec832c8837c6d6"
          }
        },
        "776ae0d5e3ba4ff9a3b086149294ce18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a967608acdf4fb2ad8dcd312a162efc",
            "placeholder": "​",
            "style": "IPY_MODEL_558dcf1820154b6b871e009258714dce",
            "value": "tokenizer.json: 100%"
          }
        },
        "8d0775572de441c38753a024fbd43663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11856cf678a44098a55c052ee2fdfa2f",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b8d7ac01a6c405b95bd00c8b0b725ee",
            "value": 1355863
          }
        },
        "d74945c034894c33bbdd2f8e96903930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e9f582510a74aa9b01dbde172aba9e3",
            "placeholder": "​",
            "style": "IPY_MODEL_74c4bf51e76c4dc6a49a7edabe67482d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.7MB/s]"
          }
        },
        "95b31e6ce8df4f1bb5ec832c8837c6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a967608acdf4fb2ad8dcd312a162efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558dcf1820154b6b871e009258714dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11856cf678a44098a55c052ee2fdfa2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8d7ac01a6c405b95bd00c8b0b725ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e9f582510a74aa9b01dbde172aba9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c4bf51e76c4dc6a49a7edabe67482d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70331336abc4c21a0d339d3d2e3413d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7454d5f46bc4bc9a7e4e0bd72c32456",
              "IPY_MODEL_00105dec1f5244fcb925a70d81d6c592",
              "IPY_MODEL_6131499f9cde401ba15be4e3f8f51ec0"
            ],
            "layout": "IPY_MODEL_687bc5db35924cfba3f79b887949f380"
          }
        },
        "a7454d5f46bc4bc9a7e4e0bd72c32456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e7f05311ae46c1b328eb688f25a3d5",
            "placeholder": "​",
            "style": "IPY_MODEL_a6652ebe07204d1da7293ae3b7a6a02d",
            "value": "Map: 100%"
          }
        },
        "00105dec1f5244fcb925a70d81d6c592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6412dd57f244d3a9ce1b6430eac1aa",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ea67270fe04495ab6cab5bed6011890",
            "value": 1000
          }
        },
        "6131499f9cde401ba15be4e3f8f51ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f31e13dee2403889dd07ed2d7c4cc5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c43f0ce161f4f59bebdded724d28737",
            "value": " 1000/1000 [00:01&lt;00:00, 901.64 examples/s]"
          }
        },
        "687bc5db35924cfba3f79b887949f380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e7f05311ae46c1b328eb688f25a3d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6652ebe07204d1da7293ae3b7a6a02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c6412dd57f244d3a9ce1b6430eac1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea67270fe04495ab6cab5bed6011890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9f31e13dee2403889dd07ed2d7c4cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c43f0ce161f4f59bebdded724d28737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be3221bb8cea44998d2924f5daca045e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac8422d8d0a94a7c8bcf11a9636ff3d0",
              "IPY_MODEL_4e3e2df564284507bf305083f2b7ee38",
              "IPY_MODEL_26108737a58f467ebd5b7cfc1b04ea71"
            ],
            "layout": "IPY_MODEL_c5ceef6c7bf9489a87c34c1b085f35c6"
          }
        },
        "ac8422d8d0a94a7c8bcf11a9636ff3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1f66f31ab84570adf5d10ebff1983f",
            "placeholder": "​",
            "style": "IPY_MODEL_e3603ab0a2c341598e3c26c889959575",
            "value": "Map: 100%"
          }
        },
        "4e3e2df564284507bf305083f2b7ee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dbba8f2e2974a099b341d4f4c818965",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f01e1c1b64cf4236ab939448f475f214",
            "value": 100
          }
        },
        "26108737a58f467ebd5b7cfc1b04ea71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_409f22e927c845d9be1a36a5b33a627c",
            "placeholder": "​",
            "style": "IPY_MODEL_a11b9ea522084471b3e39f7c6a9393b7",
            "value": " 100/100 [00:00&lt;00:00, 685.17 examples/s]"
          }
        },
        "c5ceef6c7bf9489a87c34c1b085f35c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1f66f31ab84570adf5d10ebff1983f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3603ab0a2c341598e3c26c889959575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dbba8f2e2974a099b341d4f4c818965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f01e1c1b64cf4236ab939448f475f214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "409f22e927c845d9be1a36a5b33a627c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a11b9ea522084471b3e39f7c6a9393b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "255909783c654084a3aaaacea9efb260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7e8185ee8ac42e2b83e2316122c0adb",
              "IPY_MODEL_501c11488082447cac97b3b951e49c5f",
              "IPY_MODEL_81cde7b7fe444fb7bb61f0e6ff58f07d"
            ],
            "layout": "IPY_MODEL_0cecda7e58de44aaa0edf5e6a892f1d7"
          }
        },
        "c7e8185ee8ac42e2b83e2316122c0adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39356132e838438c9991ba4ba6694547",
            "placeholder": "​",
            "style": "IPY_MODEL_c3cce9c52161433b97367c606cbe2ff4",
            "value": "config.json: 100%"
          }
        },
        "501c11488082447cac97b3b951e49c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae5879c9b63b47d89e9bdcc835071fad",
            "max": 1628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d92633344854a639c0876ad98e4097f",
            "value": 1628
          }
        },
        "81cde7b7fe444fb7bb61f0e6ff58f07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0899606e84f4e03b7d2f1c06fda7305",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6075689d364cdf887e12d7f597e21b",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 59.7kB/s]"
          }
        },
        "0cecda7e58de44aaa0edf5e6a892f1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39356132e838438c9991ba4ba6694547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cce9c52161433b97367c606cbe2ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5879c9b63b47d89e9bdcc835071fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d92633344854a639c0876ad98e4097f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0899606e84f4e03b7d2f1c06fda7305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6075689d364cdf887e12d7f597e21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f26b514830d47498b7fd83278e49953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e127f40ca946f48d2d716d5037ac45",
              "IPY_MODEL_34289f0a3313410481448fd01df18ef4",
              "IPY_MODEL_03c27fd713e54bcfb453437a20f7f047"
            ],
            "layout": "IPY_MODEL_2735b1e2608841269ce1b7d7edd0de3d"
          }
        },
        "c4e127f40ca946f48d2d716d5037ac45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_473f79de63cb404ea27be020bbaaad94",
            "placeholder": "​",
            "style": "IPY_MODEL_ce7a82b0112b41f99343bbf7c5198dc6",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "34289f0a3313410481448fd01df18ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab50a1d6debe4baca7cb42ce884ca087",
            "max": 1018571383,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d96bb3471b4f1db84d6afd2bb02a57",
            "value": 1018571383
          }
        },
        "03c27fd713e54bcfb453437a20f7f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55376d7853db425d95352ea78cde9a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_08d958527fdd4de8b71727a6f6406eb1",
            "value": " 1.02G/1.02G [00:10&lt;00:00, 178MB/s]"
          }
        },
        "2735b1e2608841269ce1b7d7edd0de3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "473f79de63cb404ea27be020bbaaad94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7a82b0112b41f99343bbf7c5198dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab50a1d6debe4baca7cb42ce884ca087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d96bb3471b4f1db84d6afd2bb02a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55376d7853db425d95352ea78cde9a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d958527fdd4de8b71727a6f6406eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "If you're opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets as well as other dependencies. Uncomment the following cell and run it."
      ],
      "metadata": {
        "id": "X4cRE8IbIrIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install torch~=2.0.0 https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-2.0-cp38-cp38-linux_x86_64.whl"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:33.718949Z",
          "iopub.execute_input": "2023-10-25T07:07:33.719890Z",
          "iopub.status.idle": "2023-10-25T07:07:33.725468Z",
          "shell.execute_reply.started": "2023-10-25T07:07:33.719855Z",
          "shell.execute_reply": "2023-10-25T07:07:33.724339Z"
        },
        "trusted": true,
        "id": "1X-15ips0lSj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub datasets evaluate transformers rouge-score nltk transformers[torch] einops"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:33.729924Z",
          "iopub.execute_input": "2023-10-25T07:07:33.730258Z",
          "iopub.status.idle": "2023-10-25T07:07:45.765883Z",
          "shell.execute_reply.started": "2023-10-25T07:07:33.730205Z",
          "shell.execute_reply": "2023-10-25T07:07:45.764436Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfpi330i0lSk",
        "outputId": "35f4fa41-97d7-4b79-975a-06c741cf5dcc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ['XLA_USE_BF16']=\"1\"\n",
        "# os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n",
        "\n",
        "# import torch\n",
        "# import pandas as pd\n",
        "# from scipy import stats\n",
        "# import numpy as np\n",
        "\n",
        "# from tqdm import tqdm\n",
        "# from collections import OrderedDict, namedtuple\n",
        "# import torch.nn as nn\n",
        "# from torch.optim import lr_scheduler\n",
        "# import joblib\n",
        "\n",
        "# import logging\n",
        "# import transformers\n",
        "# from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule, XLMRobertaTokenizer, XLMRobertaModel, XLMRobertaConfig\n",
        "# import sys\n",
        "# from sklearn import metrics, model_selection"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:45.769185Z",
          "iopub.execute_input": "2023-10-25T07:07:45.769718Z",
          "iopub.status.idle": "2023-10-25T07:07:45.777120Z",
          "shell.execute_reply.started": "2023-10-25T07:07:45.769669Z",
          "shell.execute_reply": "2023-10-25T07:07:45.776079Z"
        },
        "trusted": true,
        "id": "YYMhD9Xh0lSm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch_xla.core.xla_model as xm\n",
        "# import torch_xla.distributed.parallel_loader as pl\n",
        "# import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "# device = xm.xla_device()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:45.778601Z",
          "iopub.execute_input": "2023-10-25T07:07:45.778955Z",
          "iopub.status.idle": "2023-10-25T07:07:45.789854Z",
          "shell.execute_reply.started": "2023-10-25T07:07:45.778921Z",
          "shell.execute_reply": "2023-10-25T07:07:45.788984Z"
        },
        "trusted": true,
        "id": "4Hte2XRp0lSm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
      ],
      "metadata": {
        "id": "xDgAT1IviIFZ",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:45.793066Z",
          "iopub.execute_input": "2023-10-25T07:07:45.793901Z",
          "iopub.status.idle": "2023-10-25T07:07:47.140062Z",
          "shell.execute_reply.started": "2023-10-25T07:07:45.793865Z",
          "shell.execute_reply": "2023-10-25T07:07:47.138621Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0,1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:47.141734Z",
          "iopub.execute_input": "2023-10-25T07:07:47.142050Z",
          "iopub.status.idle": "2023-10-25T07:07:48.184526Z",
          "shell.execute_reply.started": "2023-10-25T07:07:47.142023Z",
          "shell.execute_reply": "2023-10-25T07:07:48.183323Z"
        },
        "trusted": true,
        "id": "ws6idHmZ0lSn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = \"fd78ea9bd1f15165e547ac607fa3d95c18d50433\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.186466Z",
          "iopub.execute_input": "2023-10-25T07:07:48.187788Z",
          "iopub.status.idle": "2023-10-25T07:07:48.195616Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.187746Z",
          "shell.execute_reply": "2023-10-25T07:07:48.194673Z"
        },
        "trusted": true,
        "id": "o_vCNo9d0lSn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n",
        "\n",
        "To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n",
        "\n",
        "First you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:"
      ],
      "metadata": {
        "id": "Bem2kQaviIFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you need to install Git-LFS. Uncomment the following instructions:"
      ],
      "metadata": {
        "id": "-LwLWH2WiIFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #!apt-get install git-lfs\n",
        "# !curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash"
      ],
      "metadata": {
        "id": "HSRwiC_EiIFa",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.197004Z",
          "iopub.execute_input": "2023-10-25T07:07:48.197368Z",
          "iopub.status.idle": "2023-10-25T07:07:48.205160Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.197336Z",
          "shell.execute_reply": "2023-10-25T07:07:48.203924Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
      ],
      "metadata": {
        "id": "KEoqq-6tiIFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "3rsZjvaJiIFb",
        "outputId": "2c0ca685-077a-4165-898f-29eb96e64de3",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.206491Z",
          "iopub.execute_input": "2023-10-25T07:07:48.206766Z",
          "iopub.status.idle": "2023-10-25T07:07:48.218176Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.206743Z",
          "shell.execute_reply": "2023-10-25T07:07:48.216600Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/seq2seq)."
      ],
      "metadata": {
        "id": "HFASsisvIrIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely."
      ],
      "metadata": {
        "id": "IVbKHMj3iIFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils import send_example_telemetry\n",
        "\n",
        "send_example_telemetry(\"summarization_notebook\", framework=\"pytorch\")"
      ],
      "metadata": {
        "id": "ngRm8xehiIFc",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.219992Z",
          "iopub.execute_input": "2023-10-25T07:07:48.220423Z",
          "iopub.status.idle": "2023-10-25T07:07:48.480045Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.220390Z",
          "shell.execute_reply": "2023-10-25T07:07:48.478838Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning a model on a summarization task"
      ],
      "metadata": {
        "id": "rEJBSTyZIrIb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will see how to fine-tune one of the [🤗 Transformers](https://github.com/huggingface/transformers) model for a summarization task. We will use the [XSum dataset](https://arxiv.org/pdf/1808.08745.pdf) (for extreme summarization) which contains BBC articles accompanied with single-sentence summaries.\n",
        "\n",
        "![Widget inference on a summarization task](https://github.com/huggingface/notebooks/blob/main/examples/images/summarization.png?raw=1)\n",
        "\n",
        "We will see how to easily load the dataset for this task using 🤗 Datasets and how to fine-tune a model on it using the `Trainer` API."
      ],
      "metadata": {
        "id": "kTCFado4IrIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"facebook/bart-base\""
      ],
      "metadata": {
        "id": "g6PugG96iIFd",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.486267Z",
          "iopub.execute_input": "2023-10-25T07:07:48.486665Z",
          "iopub.status.idle": "2023-10-25T07:07:48.492716Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.486629Z",
          "shell.execute_reply": "2023-10-25T07:07:48.491468Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is built to run  with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a sequence-to-sequence version in the Transformers library. Here we picked the [`t5-small`](https://huggingface.co/t5-small) checkpoint."
      ],
      "metadata": {
        "id": "4RRkXuteIrIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "whPRbBNbIrIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the [🤗 Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  "
      ],
      "metadata": {
        "id": "W7QYTpxXIrIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/GuyRobot/AINotesBook/releases/download/v1/EHealthChatDataset.json.gz\n",
        "# !gzip -d EHealthChatDataset.json.gz"
      ],
      "metadata": {
        "id": "xrRMvk-GukJI",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.494137Z",
          "iopub.execute_input": "2023-10-25T07:07:48.494545Z",
          "iopub.status.idle": "2023-10-25T07:07:48.504691Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.494503Z",
          "shell.execute_reply": "2023-10-25T07:07:48.503791Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q nlp"
      ],
      "metadata": {
        "id": "HH3UmIo7w1z-",
        "outputId": "d6fe422f-2684-494c-aa1d-8b40f5d3963b",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:07:48.506039Z",
          "iopub.execute_input": "2023-10-25T07:07:48.506353Z",
          "iopub.status.idle": "2023-10-25T07:08:00.423813Z",
          "shell.execute_reply.started": "2023-10-25T07:07:48.506326Z",
          "shell.execute_reply": "2023-10-25T07:08:00.422620Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from evaluate import load\n",
        "\n",
        "# train_ds = load_dataset(\"json\", data_files=[\"EHealthChatDataset.json\"], split=\"train[:80%]\")\n",
        "# vals_ds = load_dataset(\"json\", data_files=[\"EHealthChatDataset.json\"], split=\"train[80%:]\")"
      ],
      "metadata": {
        "id": "IreSlFmlIrIm",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:00.426364Z",
          "iopub.execute_input": "2023-10-25T07:08:00.426683Z",
          "iopub.status.idle": "2023-10-25T07:08:00.434069Z",
          "shell.execute_reply.started": "2023-10-25T07:08:00.426654Z",
          "shell.execute_reply": "2023-10-25T07:08:00.432888Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "# with open(\"EHealthChatDataset.json\") as f:\n",
        "#     data = json.load(f)\n",
        "#     train_ds = Dataset.from_pandas(pd.DataFrame(data=data[:int(len(data)*0.8)]))\n",
        "#     vals_ds = Dataset.from_pandas(pd.DataFrame(data=data[int(len(data)*0.8):]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:00.435561Z",
          "iopub.execute_input": "2023-10-25T07:08:00.436395Z",
          "iopub.status.idle": "2023-10-25T07:08:00.445542Z",
          "shell.execute_reply.started": "2023-10-25T07:08:00.436362Z",
          "shell.execute_reply": "2023-10-25T07:08:00.444581Z"
        },
        "trusted": true,
        "id": "kdBjhXsd0lSq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/GuyRobot/AINotesBook/releases/download/clean/EHealthChatDataset_seq_512.csv"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:00.446810Z",
          "iopub.execute_input": "2023-10-25T07:08:00.447158Z",
          "iopub.status.idle": "2023-10-25T07:08:03.178567Z",
          "shell.execute_reply.started": "2023-10-25T07:08:00.447129Z",
          "shell.execute_reply": "2023-10-25T07:08:03.177409Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJLNOYZY0lSq",
        "outputId": "c7defb30-9a12-45bb-b54d-310f983352d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-27 06:39:04--  https://github.com/GuyRobot/AINotesBook/releases/download/clean/EHealthChatDataset_seq_512.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/350588256/7de58201-6958-41f7-9980-5363334ed2b8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231127T063904Z&X-Amz-Expires=300&X-Amz-Signature=d78fbee446ce3bf9959b4dc350cd8610818f77d0d606ab57fcf58a504b7dc6c3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350588256&response-content-disposition=attachment%3B%20filename%3DEHealthChatDataset_seq_512.csv&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-11-27 06:39:05--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/350588256/7de58201-6958-41f7-9980-5363334ed2b8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231127T063904Z&X-Amz-Expires=300&X-Amz-Signature=d78fbee446ce3bf9959b4dc350cd8610818f77d0d606ab57fcf58a504b7dc6c3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=350588256&response-content-disposition=attachment%3B%20filename%3DEHealthChatDataset_seq_512.csv&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88000773 (84M) [application/octet-stream]\n",
            "Saving to: ‘EHealthChatDataset_seq_512.csv’\n",
            "\n",
            "EHealthChatDataset_ 100%[===================>]  83.92M   123MB/s    in 0.7s    \n",
            "\n",
            "2023-11-27 06:39:05 (123 MB/s) - ‘EHealthChatDataset_seq_512.csv’ saved [88000773/88000773]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"EHealthChatDataset_seq_512.csv\") as f:\n",
        "    data = pd.read_csv(f).dropna()\n",
        "    train_ds = Dataset.from_pandas(pd.DataFrame(data=data[:1000]))\n",
        "    vals_ds = Dataset.from_pandas(pd.DataFrame(data=data[:100]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:03.180601Z",
          "iopub.execute_input": "2023-10-25T07:08:03.181045Z",
          "iopub.status.idle": "2023-10-25T07:08:04.637112Z",
          "shell.execute_reply.started": "2023-10-25T07:08:03.181003Z",
          "shell.execute_reply": "2023-10-25T07:08:04.636114Z"
        },
        "trusted": true,
        "id": "vtSdrKmy0lSr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "raw_datasets = DatasetDict()\n",
        "raw_datasets[\"train\"] = train_ds\n",
        "raw_datasets[\"validation\"] = vals_ds\n",
        "# raw_datasets = load_dataset(\"xsum\")\n",
        "# raw_datasets = load_dataset(\"json\", data_files={\"train\": \"ehealthforumQAs.json\", \"validation\": \"ehealthforumQAs.json\"})\n",
        "metric = load(\"rouge\")"
      ],
      "metadata": {
        "id": "vFWoMd5vUg10",
        "outputId": "df1c5e44-c044-479f-d6ab-f022accf8afc",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:04.638445Z",
          "iopub.execute_input": "2023-10-25T07:08:04.639532Z",
          "iopub.status.idle": "2023-10-25T07:08:06.050556Z",
          "shell.execute_reply.started": "2023-10-25T07:08:04.639493Z",
          "shell.execute_reply": "2023-10-25T07:08:06.049545Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4fdd3390545a466882280848d76d8d41",
            "91c20d96093b4c668c1be20f2a808de8",
            "c98284291ea0414b998543459029bf3a",
            "5ece372fe5624636bd19486fd2bc8930",
            "b5c35e13e5fa4245beacab01d189c25d",
            "7832e72b4c7e4403b7d29def6b3d0daf",
            "1b82787bcb5c482684162c52c1f32941",
            "10bddf5309ec498dbfe0add08e796520",
            "305c22ea194f4ac49d470bb2a419e616",
            "70d2d11a719c4685a61ba585ab76d51f",
            "4cc5dbae9d9a432689c81dcbae6c5762"
          ]
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fdd3390545a466882280848d76d8d41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import nlp\n",
        "# dataset_cc = nlp.concatenate_datasets([train_ds, vals_ds])"
      ],
      "metadata": {
        "id": "zUTx_pwLw6qE",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.052033Z",
          "iopub.execute_input": "2023-10-25T07:08:06.052422Z",
          "iopub.status.idle": "2023-10-25T07:08:06.057955Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.052394Z",
          "shell.execute_reply": "2023-10-25T07:08:06.056896Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
      ],
      "metadata": {
        "id": "RzfPtOMoIrIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "outputId": "2f76f350-d878-4400-b324-429353dde727",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.059477Z",
          "iopub.execute_input": "2023-10-25T07:08:06.059811Z",
          "iopub.status.idle": "2023-10-25T07:08:06.071658Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.059780Z",
          "shell.execute_reply": "2023-10-25T07:08:06.070727Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Unnamed: 0.2', 'Unnamed: 0', 'Unnamed: 0.1', 'answer', 'url', 'question', '__index_level_0__'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['Unnamed: 0.2', 'Unnamed: 0', 'Unnamed: 0.1', 'answer', 'url', 'question', '__index_level_0__'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To access an actual element, you need to select a split first, then give an index:"
      ],
      "metadata": {
        "id": "u3EtYfeHIrIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets[\"train\"][0]"
      ],
      "metadata": {
        "id": "X6HrpprwIrIz",
        "outputId": "31386822-6b80-4530-cee0-f1cc114e674f",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.072942Z",
          "iopub.execute_input": "2023-10-25T07:08:06.073332Z",
          "iopub.status.idle": "2023-10-25T07:08:06.085826Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.073300Z",
          "shell.execute_reply": "2023-10-25T07:08:06.084687Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0.2': 1,\n",
              " 'Unnamed: 0': 1,\n",
              " 'Unnamed: 0.1': 1,\n",
              " 'answer': 'Gynae examination and ultrasound advised  I understand your anxiety about the issue and it is indeed serious and should\\nnot be taken lightly  Get a pelvic examination from a good gynaecologist and an ultrasound at the earliest  It can be\\nserious so much so like cancer or can just be related to postmenopausal hormone deficiency  Get the tests and then we\\ncan decide further',\n",
              " 'url': 'https://www.healthcaremagic.com/premiumquestions/What-causes-persistent-painless-vaginal-bleeding/305320',\n",
              " 'question': 'I have vaginal bleeding for three years. No pain . I would like to know why.',\n",
              " '__index_level_0__': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
      ],
      "metadata": {
        "id": "WHUmphG3IrI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "i3j8APAoIrI3",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.086768Z",
          "iopub.execute_input": "2023-10-25T07:08:06.087098Z",
          "iopub.status.idle": "2023-10-25T07:08:06.102568Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.087067Z",
          "shell.execute_reply": "2023-10-25T07:08:06.101692Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(raw_datasets[\"train\"])"
      ],
      "metadata": {
        "id": "SZy5tRB_IrI7",
        "outputId": "12a27f08-4eba-4535-bb50-a7cd3ae77759",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.103714Z",
          "iopub.execute_input": "2023-10-25T07:08:06.104504Z",
          "iopub.status.idle": "2023-10-25T07:08:06.125130Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.104469Z",
          "shell.execute_reply": "2023-10-25T07:08:06.124256Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>answer</th>\n",
              "      <th>url</th>\n",
              "      <th>question</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>609</td>\n",
              "      <td>609</td>\n",
              "      <td>609</td>\n",
              "      <td>Get examined and investigated as advised I have gone through your question and understand your concerns. Subcutaneous\\nmultiple swelling all over the body may be fat, neurofibromatosis or cysticerous.  Is there any history of seizure,\\nmotor weakness, sensory loss, visual loss? Any family history of such lesion? Biopsy or ultrasound may be required. The\\ntreatment will depend upon diagnosis. Dr  Deepti  Verma</td>\n",
              "      <td>https://www.healthcaremagic.com/premiumquestions/Suggest-treatment-for-lumps-on-the-hands-and-legs/304910</td>\n",
              "      <td>hi doctor, I have lumps under skin on hands and legs here and there. few are big in size and others are small which are not painful. I m having since 3 or 4 years. the numbers increased now than earlier.  im feeling like new ones are appearing but not very sure. what are these ? is it serious? what  treatments are available to completely cure/remove them?</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3086</td>\n",
              "      <td>3086</td>\n",
              "      <td>3086</td>\n",
              "      <td>Yes the drug will help  H C M.  Yes  Klonopin can be used to relax nerves and will relieve anxiety and stress.  You were\\n72 and avoid high dose of  Klonopin.  Dose of 0.25 will help in relaxation. Take the drugs as per prescription only.\\nThanks and  Take care.</td>\n",
              "      <td>https://www.healthcaremagic.com/premiumquestions/Is-Klonopin-effective-in-relaxing-the-muscles-and-nerves/299915</td>\n",
              "      <td>I read on line that using klonipin can help relax the nerves in the muscles when having a flare</td>\n",
              "      <td>694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>660</td>\n",
              "      <td>660</td>\n",
              "      <td>660</td>\n",
              "      <td>Ultrasound scan required  I understand your concerns.  It is difficult to say if abortion is complete.  I suggest you\\nget an ultrasound scan to identify if abortion is complete.  There is no other way to confirm it.</td>\n",
              "      <td>https://www.healthcaremagic.com/premiumquestions/How-to-confirm-if-abortion-is-complete/304866</td>\n",
              "      <td>Hello sir.. actually I'm at 8th week of pregnancy.. Nd I took unwanted kit of 5 pills... On the first day I took one pill.. after 24hrs I took 2 pills after 30mins I started bleeding nd seems to lost my ovum after 4 hrs that is early in the morning.. nd now after 48hrs took 3rd dosage of 2 pills of 200mg each.. continues to bleed... Feeling severe ache of my stomach... Still how many days I may continue to bleed?? And after how many days I can check the removed preganancy???? Please kindly provide info for me sir...!!!</td>\n",
              "      <td>158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3385</td>\n",
              "      <td>3385</td>\n",
              "      <td>3385</td>\n",
              "      <td>Consider  P T S D. H C M. I have read your question and understand your concerns. If  I was your wife's  Doctor,  I\\nwould consider post traumatic stress disorder ( P T S D), as a possible diagnosis, since all other diagnostic tests\\ndidn't result in a definitive answer and drug she used didn't improved her symptoms. Discuss with a  Neurologist/\\nPsychiatrist about these issues. If this diagnosis is strongly supported,  Zoloft is a good treatment possibility. Hope\\nyou found the answer helpful. Take care.</td>\n",
              "      <td>https://www.healthcaremagic.com/premiumquestions/Suggest-treatment-for-post-traumatic-stress-disorder/299733</td>\n",
              "      <td>My wife, a white female 48 years old has been dealing with multiple issues since we were rear ended in July 2015. She was treated for whiplash and concussion from the accident. Shortly after the accident she began having sever pain in the middle of her spine. Her family doctor ordered an MRI and no injury or issue with her spine. She also began having joint pain in her ring finger on her right hand. Additional joint pain began showing up in her hands, feet, knees, hips and now her lower back and shoulders. She was referred to a rheumatologist who treated her for psoriatic arthritis, but after 8 months determined that she didn't have inflammation per her sed rate. None of the anti-inflammatory meds did any for her symptoms. The family doctor is no treating her for fibromyalgia with gabapentin after trying cymbalta which she had major side effects to. My wife is not comfortable with this diagnoses as the family doctor has listed depression and not the fibromyalgia as her diagnosis. My wife is only depressed because she is in pain every day. She is more frustrated then depressed because of the lack of answers to her issues.</td>\n",
              "      <td>761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3123</td>\n",
              "      <td>3123</td>\n",
              "      <td>3123</td>\n",
              "      <td>C T guided biopsy    Since your doctor told you that either u had pneumonia or nodularity within right lung upper lobe i\\nsuggest u complete a 7 day course of antibiotic and then repeat  C T scan of chest with contrast and if the space\\noccupying lesion in your lungs still persist in the scan then u do a  C T guided biopsy from that lesion to rule out\\nmalignancy.  Generally pneumonic patches clear off in scan after a course of antibiotic.</td>\n",
              "      <td>https://www.healthcaremagic.com/premiumquestions/Is-persistent-nodularity-in-the-right-lung-indicative-of-cancer/108501</td>\n",
              "      <td>Hi I'm XXXXXXX XXXXXXX I was told by adoctor I have either pneumonia or nodularity within the right lung upper lobe if idon't  respond to antibiotics.Is that poosible and can you pneumni?Penelope  or I have a mass and it's probably cancer</td>\n",
              "      <td>701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metric is an instance of [`datasets.Metric`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric):"
      ],
      "metadata": {
        "id": "lnjDIuQ3IrI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric"
      ],
      "metadata": {
        "id": "5o4rUteaIrI_",
        "outputId": "050a7577-c498-48ac-be18-7e26bea1ab6f",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.126376Z",
          "iopub.execute_input": "2023-10-25T07:08:06.126711Z",
          "iopub.status.idle": "2023-10-25T07:08:06.136667Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.126679Z",
          "shell.execute_reply": "2023-10-25T07:08:06.135666Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationModule(name: \"rouge\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id=None)}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
              "Calculates average rouge scores for a list of hypotheses and references\n",
              "Args:\n",
              "    predictions: list of predictions to score. Each prediction\n",
              "        should be a string with tokens separated by spaces.\n",
              "    references: list of reference for each prediction. Each\n",
              "        reference should be a string with tokens separated by spaces.\n",
              "    rouge_types: A list of rouge types to calculate.\n",
              "        Valid names:\n",
              "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
              "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
              "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
              "\"`.\n",
              "        See details in https://github.com/huggingface/datasets/issues/617\n",
              "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
              "    use_aggregator: Return aggregates if this is set to True\n",
              "Returns:\n",
              "    rouge1: rouge_1 (f1),\n",
              "    rouge2: rouge_2 (f1),\n",
              "    rougeL: rouge_l (f1),\n",
              "    rougeLsum: rouge_lsum (f1)\n",
              "Examples:\n",
              "\n",
              "    >>> rouge = evaluate.load('rouge')\n",
              "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
              "    >>> references = [\"hello there\", \"general kenobi\"]\n",
              "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can call its `compute` method with your predictions and labels, which need to be list of decoded strings:"
      ],
      "metadata": {
        "id": "jAWdqcUBIrJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_preds = [\"hello there\", \"general kenobi\"]\n",
        "fake_labels = [\"hello there\", \"general kenobi\"]\n",
        "metric.compute(predictions=fake_preds, references=fake_labels)"
      ],
      "metadata": {
        "id": "6XN1Rq0aIrJC",
        "outputId": "42448503-aa34-4e70-fccc-f807a9f5118e",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.137826Z",
          "iopub.execute_input": "2023-10-25T07:08:06.139587Z",
          "iopub.status.idle": "2023-10-25T07:08:06.350311Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.139561Z",
          "shell.execute_reply": "2023-10-25T07:08:06.349070Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the data"
      ],
      "metadata": {
        "id": "n9qywopnIrJH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
        "\n",
        "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
        "\n",
        "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
        "- we download the vocabulary used when pretraining this specific checkpoint.\n",
        "\n",
        "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
      ],
      "metadata": {
        "id": "YVx71GdAIrJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "eXNLu_-nIrJI",
        "outputId": "0fc8bab2-7072-40ee-ca67-fd3979fb6750",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:06.351747Z",
          "iopub.execute_input": "2023-10-25T07:08:06.352096Z",
          "iopub.status.idle": "2023-10-25T07:08:07.363177Z",
          "shell.execute_reply.started": "2023-10-25T07:08:06.352065Z",
          "shell.execute_reply": "2023-10-25T07:08:07.362063Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "79ae3e641e3947e8a03dbc4e20c9c510",
            "005a505a5a4b452c95e2eb2df8e5d429",
            "f61abb9c21a64e44b291da97ac6adba5",
            "43675ab8c69a488dabebdfe6bfb768ec",
            "998ee281a4fa4217a6e4515059860ad2",
            "774eedabc0ff4da6b2cf883c9a7b4de1",
            "2a05fcbb53e74330a80cfcae51a9e32b",
            "ac80e9738f9e447ab15e2c7f0827e08c",
            "5854fbc564ab432c91076abb466c1184",
            "96a11765905649f48a8f3287cf509029",
            "00e013636189445caf410894491245f4",
            "6da50dd8f64a428098a740ed18272777",
            "92e7b78e94b947ed9e0e9ab22b9007bd",
            "ebd4e1b6e0da41719d79046b60f2e6ba",
            "7cc399ccc2d44d54bfa611ca39558825",
            "3e0ea1386fea40d98e20b87a750911a7",
            "75c96c8853874a1ca0fa5bf3467f53d9",
            "3f90207c70ed440f8d2f536f98775b8f",
            "14ff8532a83440129760ab91c0d987ed",
            "6c48509f0b7b425180bc06be777bd144",
            "f71d77e35b864b9a88bb98dbc9ae2aa8",
            "79522cd5df524bada6436f54235623a5",
            "4c66250fdaa74d4e9b1a0901d832bb10",
            "4a3b732fdec145f78de08802fb1fdf21",
            "c53bf696aeaf413c9b0bbbafc6b234d0",
            "579885f8be8b4559b4093c954ae7e93e",
            "46e249d74fb64dfa8a3ca8e43396742c",
            "ff4f588e837d4910a41ebd303f8a5ad7",
            "243f78c2655245f086481b6f5263b5a9",
            "0bb52dd3687a4fe3994e75b0a5b23b11",
            "5f384adee5cb41e49aec08fb2b428c30",
            "2af265a792254592bd7f2f4f2a63704e",
            "a9bddf41a6424a01b0dfc65732fcbb3e",
            "5c41716bf8a54b33bdc3fbdf09c197d4",
            "776ae0d5e3ba4ff9a3b086149294ce18",
            "8d0775572de441c38753a024fbd43663",
            "d74945c034894c33bbdd2f8e96903930",
            "95b31e6ce8df4f1bb5ec832c8837c6d6",
            "6a967608acdf4fb2ad8dcd312a162efc",
            "558dcf1820154b6b871e009258714dce",
            "11856cf678a44098a55c052ee2fdfa2f",
            "2b8d7ac01a6c405b95bd00c8b0b725ee",
            "3e9f582510a74aa9b01dbde172aba9e3",
            "74c4bf51e76c4dc6a49a7edabe67482d"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79ae3e641e3947e8a03dbc4e20c9c510"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6da50dd8f64a428098a740ed18272777"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c66250fdaa74d4e9b1a0901d832bb10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c41716bf8a54b33bdc3fbdf09c197d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the call above will use one of the fast tokenizers (backed by Rust) from the 🤗 Tokenizers library."
      ],
      "metadata": {
        "id": "Vl6IidfdIrJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can directly call this tokenizer on one sentence or a pair of sentences:"
      ],
      "metadata": {
        "id": "rowT4iCLIrJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"Hello, this one sentence!\")"
      ],
      "metadata": {
        "id": "a5hBlsrHIrJL",
        "outputId": "e750b667-ff9d-4c89-fb0a-54307a16d437",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.364578Z",
          "iopub.execute_input": "2023-10-25T07:08:07.364935Z",
          "iopub.status.idle": "2023-10-25T07:08:07.374327Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.364899Z",
          "shell.execute_reply": "2023-10-25T07:08:07.373149Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [0, 31414, 6, 42, 65, 3645, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
        "\n",
        "Instead of one sentence, we can pass along a list of sentences:"
      ],
      "metadata": {
        "id": "qo_0B1M2IrJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
      ],
      "metadata": {
        "id": "zmWmo1SIiIFh",
        "outputId": "6a2328fc-3921-474c-ca7a-e1051a30710d",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.375547Z",
          "iopub.execute_input": "2023-10-25T07:08:07.375902Z",
          "iopub.status.idle": "2023-10-25T07:08:07.389148Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.375844Z",
          "shell.execute_reply": "2023-10-25T07:08:07.388264Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 31414, 6, 42, 65, 3645, 328, 2], [0, 713, 16, 277, 3645, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare the targets for our model, we need to tokenize them using the `text_target` parameter. This will make sure the tokenizer uses the special tokens corresponding to the targets:"
      ],
      "metadata": {
        "id": "gfeukRDaiIFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer(text_target=[\"Hello, this one sentence!\", \"This is another sentence.\"]))"
      ],
      "metadata": {
        "id": "QXxL-gbziIFi",
        "outputId": "4cca8da8-0309-41e5-f6d4-d0ac7b52f00e",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.396530Z",
          "iopub.execute_input": "2023-10-25T07:08:07.396813Z",
          "iopub.status.idle": "2023-10-25T07:08:07.403334Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.396788Z",
          "shell.execute_reply": "2023-10-25T07:08:07.402238Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[0, 31414, 6, 42, 65, 3645, 328, 2], [0, 713, 16, 277, 3645, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using one of the five T5 checkpoints we have to prefix the inputs with \"summarize:\" (the model can also translate and it needs the prefix to know which task it has to perform)."
      ],
      "metadata": {
        "id": "2C0hcmp9IrJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\""
      ],
      "metadata": {
        "id": "a3RAu2wniIFm",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.404548Z",
          "iopub.execute_input": "2023-10-25T07:08:07.404853Z",
          "iopub.status.idle": "2023-10-25T07:08:07.413101Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.404821Z",
          "shell.execute_reply": "2023-10-25T07:08:07.412112Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
      ],
      "metadata": {
        "id": "NUh2j127iIFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 512\n",
        "max_target_length = 512\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    labels = tokenizer(text_target=examples[\"answer\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "vc0BSBLIIrJQ",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.414208Z",
          "iopub.execute_input": "2023-10-25T07:08:07.414586Z",
          "iopub.status.idle": "2023-10-25T07:08:07.423940Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.414551Z",
          "shell.execute_reply": "2023-10-25T07:08:07.422883Z"
        },
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
      ],
      "metadata": {
        "id": "0lm8ozrJIrJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_function(raw_datasets['train'][:2])"
      ],
      "metadata": {
        "id": "-b70jh26IrJS",
        "outputId": "d2e50f07-7b5c-4338-fcd1-46aa2487150e",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.425717Z",
          "iopub.execute_input": "2023-10-25T07:08:07.426044Z",
          "iopub.status.idle": "2023-10-25T07:08:07.440425Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.426012Z",
          "shell.execute_reply": "2023-10-25T07:08:07.439566Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 100, 33, 34126, 13162, 13, 130, 107, 4, 440, 2400, 479, 38, 74, 101, 7, 216, 596, 4, 2], [0, 876, 21284, 364, 611, 6457, 11483, 2407, 9, 12581, 117, 22628, 7427, 1499, 15715, 2340, 16698, 22090, 5395, 480, 7, 2178, 181, 9475, 611, 8307, 337, 12581, 2199, 7586, 2292, 17733, 4399, 571, 2368, 19, 1533, 9843, 5109, 1536, 4, 19869, 32108, 16, 30389, 7018, 9663, 7586, 33473, 6, 642, 3290, 241, 281, 6, 7049, 877, 70, 2340, 155, 377, 939, 33, 551, 1416, 7586, 127, 12079, 32, 1717, 417, 718, 1879, 6, 329, 3976, 1417, 405, 6, 462, 8538, 718, 13, 859, 7586, 78, 127, 2292, 17733, 21, 753, 4, 245, 13753, 2156, 485, 266, 924, 545, 13753, 31617, 853, 1792, 179, 12, 134, 4, 466, 2642, 179, 12, 306, 4, 245, 37544, 27377, 12, 176, 4, 245, 579, 22371, 12, 2518, 579, 571, 3320, 12, 1558, 38994, 38204, 34637, 41278, 12, 4156, 1437, 1437, 127, 12581, 1836, 21, 361, 4, 245, 13753, 4, 1437, 178, 130, 377, 41268, 338, 127, 2292, 17733, 2906, 7, 545, 4, 245, 13753, 8, 9843, 5109, 1536, 1836, 2906, 4528, 910, 127, 266, 21958, 11, 570, 1577, 48193, 18313, 1437, 11378, 162, 549, 24, 16, 33370, 890, 868, 50, 24, 8349, 2017, 7, 40441, 20378, 13310, 7586, 98, 939, 240, 14067, 734, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 939, 351, 75, 4076, 50, 4603, 7586, 8, 5171, 9, 45441, 741, 6, 438, 385, 7586, 479, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1437, 1892, 528, 7, 173, 939, 439, 7, 277, 1098, 7586, 89, 1437, 71, 65, 39750, 939, 362, 14194, 122, 456, 127, 2292, 17733, 1411, 7, 291, 13753, 29942, 259, 51, 2294, 1437, 1717, 417, 718, 1879, 9995, 1236, 620, 51, 1311, 129, 65, 9995, 8462, 38315, 13, 94, 130, 377, 29942, 277, 181, 3662, 119, 528, 7, 2292, 17733, 21, 5299, 10219, 2107, 151, 8, 885, 23219, 3788, 7586, 27882, 244, 162, 99, 939, 197, 109, 13, 42, 7586, 1219, 13, 127, 12581, 936, 21, 4727, 7586, 53, 122, 259, 51, 32, 584, 189, 71, 195, 50, 158, 1423, 4926, 47, 240, 14067, 734, 11, 78, 1098, 51, 174, 24, 16, 33370, 890, 5084, 47, 230, 16966, 120, 110, 2530, 1836, 12581, 53, 1717, 64, 24059, 110, 30223, 9, 12581, 4, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[0, 534, 3892, 4791, 9027, 8, 29976, 5578, 1437, 38, 1346, 110, 6882, 59, 5, 696, 8, 24, 16, 5329, 1473, 8, 197, 50118, 3654, 28, 551, 14998, 1437, 2315, 10, 38346, 9027, 31, 10, 205, 821, 19577, 3204, 6393, 8, 41, 29976, 23, 5, 13342, 1437, 85, 64, 28, 50118, 21231, 98, 203, 98, 101, 1668, 50, 64, 95, 28, 1330, 7, 618, 2262, 42363, 20940, 30367, 1437, 2315, 5, 3457, 8, 172, 52, 50118, 7424, 2845, 617, 2], [0, 40181, 55, 335, 4557, 13, 6016, 110, 25860, 4, 38, 524, 1437, 925, 4, 248, 4, 229, 8, 1437, 38, 524, 4343, 7, 3991, 47, 4, 38, 240, 103, 55, 50118, 31480, 137, 1437, 38, 64, 492, 127, 2979, 4, 38, 74, 101, 7, 33, 103, 55, 335, 137, 1437, 38, 64, 492, 127, 2979, 4, 134, 4, 50118, 32112, 19961, 1001, 43511, 50, 10, 12581, 4003, 33716, 626, 116, 176, 4, 1437, 6871, 253, 17591, 16572, 626, 116, 246, 4, 1437, 3945, 47, 10, 33560, 116, 925, 4, 248, 4, 229, 4, 2]]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
      ],
      "metadata": {
        "id": "zS-6iXTkIrJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "DDtsaJeVIrJT",
        "outputId": "cc46a563-d5e2-4037-a438-0533e71b2982",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.442138Z",
          "iopub.execute_input": "2023-10-25T07:08:07.442610Z",
          "iopub.status.idle": "2023-10-25T07:08:07.868377Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.442573Z",
          "shell.execute_reply": "2023-10-25T07:08:07.867192Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b70331336abc4c21a0d339d3d2e3413d",
            "a7454d5f46bc4bc9a7e4e0bd72c32456",
            "00105dec1f5244fcb925a70d81d6c592",
            "6131499f9cde401ba15be4e3f8f51ec0",
            "687bc5db35924cfba3f79b887949f380",
            "82e7f05311ae46c1b328eb688f25a3d5",
            "a6652ebe07204d1da7293ae3b7a6a02d",
            "2c6412dd57f244d3a9ce1b6430eac1aa",
            "8ea67270fe04495ab6cab5bed6011890",
            "c9f31e13dee2403889dd07ed2d7c4cc5",
            "1c43f0ce161f4f59bebdded724d28737",
            "be3221bb8cea44998d2924f5daca045e",
            "ac8422d8d0a94a7c8bcf11a9636ff3d0",
            "4e3e2df564284507bf305083f2b7ee38",
            "26108737a58f467ebd5b7cfc1b04ea71",
            "c5ceef6c7bf9489a87c34c1b085f35c6",
            "3f1f66f31ab84570adf5d10ebff1983f",
            "e3603ab0a2c341598e3c26c889959575",
            "8dbba8f2e2974a099b341d4f4c818965",
            "f01e1c1b64cf4236ab939448f475f214",
            "409f22e927c845d9be1a36a5b33a627c",
            "a11b9ea522084471b3e39f7c6a9393b7"
          ]
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b70331336abc4c21a0d339d3d2e3413d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be3221bb8cea44998d2924f5daca045e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
        "\n",
        "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
      ],
      "metadata": {
        "id": "voWiw8C7IrJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model"
      ],
      "metadata": {
        "id": "545PP3o8IrJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is ready, we can download the pretrained model and fine-tune it. Since our task is of the sequence-to-sequence kind, we use the `AutoModelForSeq2SeqLM` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us."
      ],
      "metadata": {
        "id": "FBiW8UpKIrJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2021 The Fairseq Authors and The HuggingFace Inc. team. All rights reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" PyTorch BART model.\"\"\"\n",
        "import copy\n",
        "import math\n",
        "import warnings\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "import torch\n",
        "import torch.utils.checkpoint\n",
        "from torch import nn, einsum\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
        "\n",
        "from transformers.activations import ACT2FN\n",
        "from transformers.modeling_outputs import (\n",
        "    BaseModelOutput,\n",
        "    BaseModelOutputWithPastAndCrossAttentions,\n",
        "    CausalLMOutputWithCrossAttentions,\n",
        "    Seq2SeqLMOutput,\n",
        "    Seq2SeqModelOutput,\n",
        "    Seq2SeqQuestionAnsweringModelOutput,\n",
        "    Seq2SeqSequenceClassifierOutput,\n",
        ")\n",
        "from transformers.modeling_utils import PreTrainedModel\n",
        "from transformers.utils import (\n",
        "    add_code_sample_docstrings,\n",
        "    add_end_docstrings,\n",
        "    add_start_docstrings,\n",
        "    add_start_docstrings_to_model_forward,\n",
        "    logging,\n",
        "    replace_return_docstrings,\n",
        ")\n",
        "from transformers.models.bart.configuration_bart import BartConfig\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)\n",
        "\n",
        "_CHECKPOINT_FOR_DOC = \"facebook/bart-base\"\n",
        "_CONFIG_FOR_DOC = \"BartConfig\"\n",
        "\n",
        "# Base model docstring\n",
        "_EXPECTED_OUTPUT_SHAPE = [1, 8, 768]\n",
        "\n",
        "# SequenceClassification docstring\n",
        "_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION = \"valhalla/bart-large-sst2\"\n",
        "_SEQ_CLASS_EXPECTED_LOSS = 0.0\n",
        "_SEQ_CLASS_EXPECTED_OUTPUT = \"'POSITIVE'\"\n",
        "\n",
        "# QuestionAsnwering docstring\n",
        "_CHECKPOINT_FOR_QA = \"valhalla/bart-large-finetuned-squadv1\"\n",
        "_QA_EXPECTED_LOSS = 0.59\n",
        "_QA_EXPECTED_OUTPUT = \"' nice puppet'\"\n",
        "\n",
        "\n",
        "BART_PRETRAINED_MODEL_ARCHIVE_LIST = [\n",
        "    \"facebook/bart-large\",\n",
        "    # see all BART models at https://huggingface.co/models?filter=bart\n",
        "]\n",
        "\n",
        "\n",
        "def shift_tokens_right(input_ids: torch.Tensor, pad_token_id: int, decoder_start_token_id: int):\n",
        "    \"\"\"\n",
        "    Shift input ids one token to the right.\n",
        "    \"\"\"\n",
        "    shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n",
        "    shifted_input_ids[:, 1:] = input_ids[:, :-1].clone()\n",
        "    shifted_input_ids[:, 0] = decoder_start_token_id\n",
        "\n",
        "    if pad_token_id is None:\n",
        "        raise ValueError(\"self.model.config.pad_token_id has to be defined.\")\n",
        "    # replace possible -100 values in labels by `pad_token_id`\n",
        "    shifted_input_ids.masked_fill_(shifted_input_ids == -100, pad_token_id)\n",
        "\n",
        "    return shifted_input_ids\n",
        "\n",
        "\n",
        "def _make_causal_mask(\n",
        "    input_ids_shape: torch.Size, dtype: torch.dtype, device: torch.device, past_key_values_length: int = 0\n",
        "):\n",
        "    \"\"\"\n",
        "    Make causal mask used for bi-directional self-attention.\n",
        "    \"\"\"\n",
        "    bsz, tgt_len = input_ids_shape\n",
        "    mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).min, device=device)\n",
        "    mask_cond = torch.arange(mask.size(-1), device=device)\n",
        "    mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n",
        "    mask = mask.to(dtype)\n",
        "\n",
        "    if past_key_values_length > 0:\n",
        "        mask = torch.cat([torch.zeros(tgt_len, past_key_values_length, dtype=dtype, device=device), mask], dim=-1)\n",
        "    return mask[None, None, :, :].expand(bsz, 1, tgt_len, tgt_len + past_key_values_length)\n",
        "\n",
        "\n",
        "def _expand_mask(mask: torch.Tensor, dtype: torch.dtype, tgt_len: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n",
        "    \"\"\"\n",
        "    bsz, src_len = mask.size()\n",
        "    tgt_len = tgt_len if tgt_len is not None else src_len\n",
        "\n",
        "    expanded_mask = mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)\n",
        "\n",
        "    inverted_mask = 1.0 - expanded_mask\n",
        "\n",
        "    return inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\n",
        "\n",
        "\n",
        "class BartLearnedPositionalEmbedding(nn.Embedding):\n",
        "    \"\"\"\n",
        "    This module learns positional embeddings up to a fixed maximum size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_embeddings: int, embedding_dim: int):\n",
        "        # Bart is set up so that if padding_idx is specified then offset the embedding ids by 2\n",
        "        # and adjust num_embeddings appropriately. Other models don't have this hack\n",
        "        self.offset = 2\n",
        "        super().__init__(num_embeddings + self.offset, embedding_dim)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, past_key_values_length: int = 0):\n",
        "        \"\"\"`input_ids' shape is expected to be [bsz x seqlen].\"\"\"\n",
        "\n",
        "        bsz, seq_len = input_ids.shape[:2]\n",
        "        positions = torch.arange(\n",
        "            past_key_values_length, past_key_values_length + seq_len, dtype=torch.long, device=self.weight.device\n",
        "        ).expand(bsz, -1)\n",
        "\n",
        "        return super().forward(positions + self.offset)\n",
        "\n",
        "\n",
        "class BartAttention(nn.Module):\n",
        "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim: int,\n",
        "        num_heads: int,\n",
        "        dropout: float = 0.0,\n",
        "        is_decoder: bool = False,\n",
        "        bias: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        # Re-attention\n",
        "        self.reatten_matrix = nn.Parameter(torch.randn(self.num_heads, self.num_heads))\n",
        "\n",
        "        if (self.head_dim * num_heads) != self.embed_dim:\n",
        "            raise ValueError(\n",
        "                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim}\"\n",
        "                f\" and `num_heads`: {num_heads}).\"\n",
        "            )\n",
        "        self.scaling = self.head_dim**-0.5\n",
        "        self.reatten_scale = self.scaling\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias)\n",
        "        self.proj_drop = nn.Dropout(0.0)\n",
        "        self.attn_drop = nn.Dropout(0.0)\n",
        "\n",
        "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
        "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        key_value_states: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        output_attentions: bool = False,\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
        "\n",
        "        # if key_value_states are provided this layer is used as a cross-attention layer\n",
        "        # for the decoder\n",
        "        re_attention = False\n",
        "        is_cross_attention = key_value_states is not None\n",
        "\n",
        "        bsz, tgt_len, _ = hidden_states.size()\n",
        "\n",
        "        # get query proj\n",
        "        query_states = self.q_proj(hidden_states) * self.scaling\n",
        "        # get key, value proj\n",
        "        # `past_key_value[0].shape[2] == key_value_states.shape[1]`\n",
        "        # is checking that the `sequence_length` of the `past_key_value` is the same as\n",
        "        # the provided `key_value_states` to support prefix tuning\n",
        "        if (\n",
        "            is_cross_attention\n",
        "            and past_key_value is not None\n",
        "            and past_key_value[0].shape[2] == key_value_states.shape[1]\n",
        "        ):\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_states = past_key_value[0]\n",
        "            value_states = past_key_value[1]\n",
        "        elif is_cross_attention:\n",
        "            # cross_attentions\n",
        "            key_states = self._shape(self.k_proj(key_value_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(key_value_states), -1, bsz)\n",
        "        elif past_key_value is not None:\n",
        "            # reuse k, v, self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "            key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
        "            value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
        "            # re_attention = True\n",
        "        else:\n",
        "            # self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "            re_attention = True\n",
        "\n",
        "        if self.is_decoder:\n",
        "            # if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\n",
        "            # Further calls to cross_attention layer can then reuse all cross-attention\n",
        "            # key/value_states (first \"if\" case)\n",
        "            # if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of\n",
        "            # all previous decoder key/value_states. Further calls to uni-directional self-attention\n",
        "            # can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\n",
        "            # if encoder bi-directional self-attention `past_key_value` is always `None`\n",
        "            past_key_value = (key_states, value_states)\n",
        "\n",
        "        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n",
        "        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
        "        key_states = key_states.reshape(*proj_shape)\n",
        "        value_states = value_states.reshape(*proj_shape)\n",
        "\n",
        "        src_len = key_states.size(1)\n",
        "        attn_weights = torch.bmm(query_states, key_states.transpose(1, 2))\n",
        "\n",
        "        if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
        "            raise ValueError(\n",
        "                f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is\"\n",
        "                f\" {attn_weights.size()}\"\n",
        "            )\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
        "                raise ValueError(\n",
        "                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "        # Re-attention\n",
        "#         if re_attention:\n",
        "# #         attn_weights = self.attn_drop(attn_weights)\n",
        "#             attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "#             attn_weights = einsum('b h i j, h g -> b g i j', attn_weights, self.reatten_matrix) * self.reatten_scale\n",
        "#             attn_weights = self.reattn_norm(attn_weights)\n",
        "#             attn_weights = attn_weights.contiguous().view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if layer_head_mask is not None:\n",
        "            if layer_head_mask.size() != (self.num_heads,):\n",
        "                raise ValueError(\n",
        "                    f\"Head mask for a single layer should be of size {(self.num_heads,)}, but is\"\n",
        "                    f\" {layer_head_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = layer_head_mask.view(1, -1, 1, 1) * attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            # attn_weights = einsum('b h i j, h g -> b g i j', attn_weights, self.reatten_matrix) * self.reatten_scale\n",
        "            # attn_weights = self.reattn_norm(attn_weights)\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        # print(\"output_attentions: \", output_attentions)\n",
        "        if output_attentions:\n",
        "            # this operation is a bit awkward, but it's required to\n",
        "            # make sure that attn_weights keeps its gradient.\n",
        "            # In order to do so, attn_weights have to be reshaped\n",
        "            # twice and have to be reused in the following\n",
        "            attn_weights_reshaped = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            # attn_weights_reshaped = einsum('b h i j, h g -> b g i j', attn_weights_reshaped, self.reatten_matrix) * self.reatten_scale\n",
        "            # attn_weights_reshaped = self.reattn_norm(attn_weights_reshaped)\n",
        "            attn_weights_reshaped = attn_weights_reshaped.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "        else:\n",
        "            attn_weights_reshaped = None\n",
        "\n",
        "        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n",
        "\n",
        "        if re_attention:\n",
        "#         attn_weights = self.attn_drop(attn_weights)\n",
        "            attn_probs = attn_probs.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_probs = einsum('b h i j, h g -> b g i j', attn_probs, self.reatten_matrix) * self.reatten_scale\n",
        "            # attn_probs = self.reattn_norm(attn_probs)\n",
        "            attn_probs = attn_probs.contiguous().view(bsz * self.num_heads, tgt_len, src_len)\n",
        "        attn_output = torch.bmm(attn_probs, value_states)\n",
        "\n",
        "        if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
        "            raise ValueError(\n",
        "                f\"`attn_output` should be of size {(bsz * self.num_heads, tgt_len, self.head_dim)}, but is\"\n",
        "                f\" {attn_output.size()}\"\n",
        "            )\n",
        "\n",
        "        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n",
        "        attn_output = attn_output.transpose(1, 2)\n",
        "\n",
        "        # Use the `embed_dim` from the config (stored in the class) rather than `hidden_state` because `attn_output` can be\n",
        "        # partitioned across GPUs when using tensor-parallelism.\n",
        "        attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)\n",
        "\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "\n",
        "        return attn_output, attn_weights_reshaped, past_key_value\n",
        "\n",
        "\n",
        "class BartEncoderLayer(nn.Module):\n",
        "    def __init__(self, config: BartConfig):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.d_model\n",
        "        self.self_attn = BartAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=config.encoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "        )\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.dropout = config.dropout\n",
        "        self.activation_fn = ACT2FN[config.activation_function]\n",
        "        self.activation_dropout = config.activation_dropout\n",
        "        self.fc1 = nn.Linear(self.embed_dim, config.encoder_ffn_dim)\n",
        "        self.fc2 = nn.Linear(config.encoder_ffn_dim, self.embed_dim)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.FloatTensor,\n",
        "        attention_mask: torch.FloatTensor,\n",
        "        layer_head_mask: torch.FloatTensor,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[torch.FloatTensor]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
        "            attention_mask (`torch.FloatTensor`): attention mask of size\n",
        "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
        "            layer_head_mask (`torch.FloatTensor`): mask for attention heads in a given layer of size\n",
        "                `(encoder_attention_heads,)`.\n",
        "            output_attentions (`bool`, *optional*):\n",
        "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "                returned tensors for more detail.\n",
        "        \"\"\"\n",
        "        residual = hidden_states\n",
        "        hidden_states, attn_weights, _ = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        if hidden_states.dtype == torch.float16 and (\n",
        "            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n",
        "        ):\n",
        "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
        "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (attn_weights,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BartDecoderLayer(nn.Module):\n",
        "    def __init__(self, config: BartConfig):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.d_model\n",
        "\n",
        "        self.self_attn = BartAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "        )\n",
        "        self.dropout = config.dropout\n",
        "        self.activation_fn = ACT2FN[config.activation_function]\n",
        "        self.activation_dropout = config.activation_dropout\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.encoder_attn = BartAttention(\n",
        "            self.embed_dim,\n",
        "            config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "        )\n",
        "        self.encoder_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.fc1 = nn.Linear(self.embed_dim, config.decoder_ffn_dim)\n",
        "        self.fc2 = nn.Linear(config.decoder_ffn_dim, self.embed_dim)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        use_cache: Optional[bool] = True,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\n",
        "            attention_mask (`torch.FloatTensor`): attention mask of size\n",
        "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
        "            encoder_hidden_states (`torch.FloatTensor`):\n",
        "                cross attention input to the layer of shape `(batch, seq_len, embed_dim)`\n",
        "            encoder_attention_mask (`torch.FloatTensor`): encoder attention mask of size\n",
        "                `(batch, 1, tgt_len, src_len)` where padding elements are indicated by very large negative values.\n",
        "            layer_head_mask (`torch.FloatTensor`): mask for attention heads in a given layer of size\n",
        "                `(encoder_attention_heads,)`.\n",
        "            cross_attn_layer_head_mask (`torch.FloatTensor`): mask for cross-attention heads in a given layer of\n",
        "                size `(decoder_attention_heads,)`.\n",
        "            past_key_value (`Tuple(torch.FloatTensor)`): cached past key and value projection states\n",
        "            output_attentions (`bool`, *optional*):\n",
        "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "                returned tensors for more detail.\n",
        "        \"\"\"\n",
        "        residual = hidden_states\n",
        "\n",
        "        # Self Attention\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "        # add present self-attn cache to positions 1,2 of present_key_value tuple\n",
        "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        # Cross-Attention Block\n",
        "        cross_attn_present_key_value = None\n",
        "        cross_attn_weights = None\n",
        "        if encoder_hidden_states is not None:\n",
        "            residual = hidden_states\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n",
        "                hidden_states=hidden_states,\n",
        "                key_value_states=encoder_hidden_states,\n",
        "                attention_mask=encoder_attention_mask,\n",
        "                layer_head_mask=cross_attn_layer_head_mask,\n",
        "                past_key_value=cross_attn_past_key_value,\n",
        "                output_attentions=output_attentions,\n",
        "            )\n",
        "            hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "            hidden_states = residual + hidden_states\n",
        "            hidden_states = self.encoder_attn_layer_norm(hidden_states)\n",
        "\n",
        "            # add cross-attn to positions 3,4 of present_key_value tuple\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        # Fully Connected\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (self_attn_weights, cross_attn_weights)\n",
        "\n",
        "        if use_cache:\n",
        "            outputs += (present_key_value,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class BartClassificationHead(nn.Module):\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        inner_dim: int,\n",
        "        num_classes: int,\n",
        "        pooler_dropout: float,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(input_dim, inner_dim)\n",
        "        self.dropout = nn.Dropout(p=pooler_dropout)\n",
        "        self.out_proj = nn.Linear(inner_dim, num_classes)\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.dense(hidden_states)\n",
        "        hidden_states = torch.tanh(hidden_states)\n",
        "        hidden_states = self.dropout(hidden_states)\n",
        "        hidden_states = self.out_proj(hidden_states)\n",
        "        return hidden_states\n",
        "\n",
        "\n",
        "class BartPreTrainedModel(PreTrainedModel):\n",
        "    config_class = BartConfig\n",
        "    base_model_prefix = \"model\"\n",
        "    supports_gradient_checkpointing = True\n",
        "    _keys_to_ignore_on_load_unexpected = [\"encoder.version\", \"decoder.version\"]\n",
        "    _no_split_modules = [r\"BartEncoderLayer\", r\"BartDecoderLayer\"]\n",
        "    _skip_keys_device_placement = \"past_key_values\"\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = self.config.init_std\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "\n",
        "    def _set_gradient_checkpointing(self, module, value=False):\n",
        "        if isinstance(module, (BartDecoder, BartEncoder)):\n",
        "            module.gradient_checkpointing = value\n",
        "\n",
        "    @property\n",
        "    def dummy_inputs(self):\n",
        "        pad_token = self.config.pad_token_id\n",
        "        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n",
        "        dummy_inputs = {\n",
        "            \"attention_mask\": input_ids.ne(pad_token),\n",
        "            \"input_ids\": input_ids,\n",
        "        }\n",
        "        return dummy_inputs\n",
        "\n",
        "\n",
        "class PretrainedBartModel(BartPreTrainedModel):\n",
        "    def __init_subclass__(self):\n",
        "        warnings.warn(\n",
        "            \"The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\",\n",
        "            FutureWarning,\n",
        "        )\n",
        "\n",
        "\n",
        "class BartPretrainedModel(BartPreTrainedModel):\n",
        "    def __init_subclass__(self):\n",
        "        warnings.warn(\n",
        "            \"The class `PretrainedBartModel` has been depreciated, please use `BartPreTrainedModel` instead.\",\n",
        "            FutureWarning,\n",
        "        )\n",
        "\n",
        "\n",
        "BART_START_DOCSTRING = r\"\"\"\n",
        "    This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
        "    library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
        "    etc.)\n",
        "\n",
        "    This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
        "    Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
        "    and behavior.\n",
        "\n",
        "    Parameters:\n",
        "        config ([`BartConfig`]):\n",
        "            Model configuration class with all the parameters of the model. Initializing with a config file does not\n",
        "            load the weights associated with the model, only the configuration. Check out the\n",
        "            [`~PreTrainedModel.from_pretrained`] method to load the model weights.\n",
        "\"\"\"\n",
        "\n",
        "BART_GENERATION_EXAMPLE = r\"\"\"\n",
        "    Summarization example:\n",
        "\n",
        "    ```python\n",
        "    >>> from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "    >>> model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "    >>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "\n",
        "    >>> ARTICLE_TO_SUMMARIZE = (\n",
        "    ...     \"PG&E stated it scheduled the blackouts in response to forecasts for high winds \"\n",
        "    ...     \"amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were \"\n",
        "    ...     \"scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\n",
        "    ... )\n",
        "    >>> inputs = tokenizer([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors=\"pt\")\n",
        "\n",
        "    >>> # Generate Summary\n",
        "    >>> summary_ids = model.generate(inputs[\"input_ids\"], num_beams=2, min_length=0, max_length=20)\n",
        "    >>> tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    'PG&E scheduled the blackouts in response to forecasts for high winds amid dry conditions'\n",
        "    ```\n",
        "\n",
        "    Mask filling example:\n",
        "\n",
        "    ```python\n",
        "    >>> from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "\n",
        "    >>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "    >>> model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "    >>> TXT = \"My friends are <mask> but they eat too many carbs.\"\n",
        "    >>> input_ids = tokenizer([TXT], return_tensors=\"pt\")[\"input_ids\"]\n",
        "    >>> logits = model(input_ids).logits\n",
        "\n",
        "    >>> masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n",
        "    >>> probs = logits[0, masked_index].softmax(dim=0)\n",
        "    >>> values, predictions = probs.topk(5)\n",
        "\n",
        "    >>> tokenizer.decode(predictions).split()\n",
        "    ['not', 'good', 'healthy', 'great', 'very']\n",
        "    ```\n",
        "\"\"\"\n",
        "\n",
        "BART_INPUTS_DOCSTRING = r\"\"\"\n",
        "    Args:\n",
        "        input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "            Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you provide\n",
        "            it.\n",
        "\n",
        "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "            [`PreTrainedTokenizer.__call__`] for details.\n",
        "\n",
        "            [What are input IDs?](../glossary#input-ids)\n",
        "        attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 for tokens that are **not masked**,\n",
        "            - 0 for tokens that are **masked**.\n",
        "\n",
        "            [What are attention masks?](../glossary#attention-mask)\n",
        "        decoder_input_ids (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
        "            Indices of decoder input sequence tokens in the vocabulary.\n",
        "\n",
        "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "            [`PreTrainedTokenizer.__call__`] for details.\n",
        "\n",
        "            [What are decoder input IDs?](../glossary#decoder-input-ids)\n",
        "\n",
        "            Bart uses the `eos_token_id` as the starting token for `decoder_input_ids` generation. If `past_key_values`\n",
        "            is used, optionally only the last `decoder_input_ids` have to be input (see `past_key_values`).\n",
        "\n",
        "            For translation and summarization training, `decoder_input_ids` should be provided. If no\n",
        "            `decoder_input_ids` is provided, the model will create this tensor by shifting the `input_ids` to the right\n",
        "            for denoising pre-training following the paper.\n",
        "        decoder_attention_mask (`torch.LongTensor` of shape `(batch_size, target_sequence_length)`, *optional*):\n",
        "            Default behavior: generate a tensor that ignores pad tokens in `decoder_input_ids`. Causal mask will also\n",
        "            be used by default.\n",
        "\n",
        "            If you want to change padding behavior, you should read [`modeling_bart._prepare_decoder_attention_mask`]\n",
        "            and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more\n",
        "            information on the default strategy.\n",
        "        head_mask (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):\n",
        "            Mask to nullify selected heads of the attention modules in the encoder. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        decoder_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "            Mask to nullify selected heads of the attention modules in the decoder. Mask values selected in `[0, 1]`:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        cross_attn_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "            Mask to nullify selected heads of the cross-attention modules in the decoder. Mask values selected in `[0,\n",
        "            1]`:\n",
        "\n",
        "            - 1 indicates the head is **not masked**,\n",
        "            - 0 indicates the head is **masked**.\n",
        "\n",
        "        encoder_outputs (`tuple(tuple(torch.FloatTensor)`, *optional*):\n",
        "            Tuple consists of (`last_hidden_state`, *optional*: `hidden_states`, *optional*: `attentions`)\n",
        "            `last_hidden_state` of shape `(batch_size, sequence_length, hidden_size)`, *optional*) is a sequence of\n",
        "            hidden-states at the output of the last layer of the encoder. Used in the cross-attention of the decoder.\n",
        "        past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
        "            Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of shape\n",
        "            `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of shape\n",
        "            `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n",
        "\n",
        "            Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention\n",
        "            blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n",
        "\n",
        "            If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those that\n",
        "            don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of all\n",
        "            `decoder_input_ids` of shape `(batch_size, sequence_length)`. inputs_embeds (`torch.FloatTensor` of shape\n",
        "            `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing `input_ids` you\n",
        "            can choose to directly pass an embedded representation. This is useful if you want more control over how to\n",
        "            convert `input_ids` indices into associated vectors than the model's internal embedding lookup matrix.\n",
        "        decoder_inputs_embeds (`torch.FloatTensor` of shape `(batch_size, target_sequence_length, hidden_size)`, *optional*):\n",
        "            Optionally, instead of passing `decoder_input_ids` you can choose to directly pass an embedded\n",
        "            representation. If `past_key_values` is used, optionally only the last `decoder_inputs_embeds` have to be\n",
        "            input (see `past_key_values`). This is useful if you want more control over how to convert\n",
        "            `decoder_input_ids` indices into associated vectors than the model's internal embedding lookup matrix.\n",
        "\n",
        "            If `decoder_input_ids` and `decoder_inputs_embeds` are both unset, `decoder_inputs_embeds` takes the value\n",
        "            of `inputs_embeds`.\n",
        "        use_cache (`bool`, *optional*):\n",
        "            If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n",
        "            `past_key_values`).\n",
        "        output_attentions (`bool`, *optional*):\n",
        "            Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
        "            tensors for more detail.\n",
        "        output_hidden_states (`bool`, *optional*):\n",
        "            Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
        "            more detail.\n",
        "        return_dict (`bool`, *optional*):\n",
        "            Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class BartEncoder(BartPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer is a\n",
        "    [`BartEncoderLayer`].\n",
        "\n",
        "    Args:\n",
        "        config: BartConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: BartConfig, embed_tokens: Optional[nn.Embedding] = None):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.encoder_layerdrop\n",
        "\n",
        "        embed_dim = config.d_model\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_source_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n",
        "\n",
        "        self.embed_tokens = nn.Embedding(config.vocab_size, embed_dim, self.padding_idx)\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens.weight = embed_tokens.weight\n",
        "\n",
        "        self.embed_positions = BartLearnedPositionalEmbedding(\n",
        "            config.max_position_embeddings,\n",
        "            embed_dim,\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BartEncoderLayer(config) for _ in range(config.encoder_layers)])\n",
        "        self.layernorm_embedding = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, BaseModelOutput]:\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n",
        "                provide it.\n",
        "\n",
        "                Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "                [`PreTrainedTokenizer.__call__`] for details.\n",
        "\n",
        "                [What are input IDs?](../glossary#input-ids)\n",
        "            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 for tokens that are **not masked**,\n",
        "                - 0 for tokens that are **masked**.\n",
        "\n",
        "                [What are attention masks?](../glossary#attention-mask)\n",
        "            head_mask (`torch.Tensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):\n",
        "                Mask to nullify selected heads of the attention modules. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 indicates the head is **not masked**,\n",
        "                - 0 indicates the head is **masked**.\n",
        "\n",
        "            inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
        "                Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation.\n",
        "                This is useful if you want more control over how to convert `input_ids` indices into associated vectors\n",
        "                than the model's internal embedding lookup matrix.\n",
        "            output_attentions (`bool`, *optional*):\n",
        "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "                returned tensors for more detail.\n",
        "            output_hidden_states (`bool`, *optional*):\n",
        "                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n",
        "                for more detail.\n",
        "            return_dict (`bool`, *optional*):\n",
        "                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
        "        \"\"\"\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input = input_ids\n",
        "            input_ids = input_ids.view(-1, input_ids.shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input = inputs_embeds[:, :, -1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
        "\n",
        "        embed_pos = self.embed_positions(input)\n",
        "        embed_pos = embed_pos.to(inputs_embeds.device)\n",
        "\n",
        "        hidden_states = inputs_embeds + embed_pos\n",
        "        hidden_states = self.layernorm_embedding(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        # expand attention_mask\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            attention_mask = _expand_mask(attention_mask, inputs_embeds.dtype)\n",
        "\n",
        "        encoder_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        # check if head_mask has a correct number of layers specified if desired\n",
        "        if head_mask is not None:\n",
        "            if head_mask.size()[0] != (len(self.layers)):\n",
        "                raise ValueError(\n",
        "                    f\"The head_mask should be specified for {len(self.layers)} layers, but it is for\"\n",
        "                    f\" {head_mask.size()[0]}.\"\n",
        "                )\n",
        "\n",
        "        for idx, encoder_layer in enumerate(self.layers):\n",
        "            if output_hidden_states:\n",
        "                encoder_states = encoder_states + (hidden_states,)\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            to_drop = False\n",
        "            if self.training:\n",
        "                dropout_probability = torch.rand([])\n",
        "                if dropout_probability < self.layerdrop:  # skip the layer\n",
        "                    to_drop = True\n",
        "\n",
        "            if to_drop:\n",
        "                layer_outputs = (None, None)\n",
        "            else:\n",
        "                if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                    def create_custom_forward(module):\n",
        "                        def custom_forward(*inputs):\n",
        "                            return module(*inputs, output_attentions)\n",
        "\n",
        "                        return custom_forward\n",
        "\n",
        "                    layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                        create_custom_forward(encoder_layer),\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        (head_mask[idx] if head_mask is not None else None),\n",
        "                    )\n",
        "                else:\n",
        "                    layer_outputs = encoder_layer(\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                        output_attentions=output_attentions,\n",
        "                    )\n",
        "\n",
        "                hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            encoder_states = encoder_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n",
        "        )\n",
        "\n",
        "\n",
        "class BartDecoder(BartPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer decoder consisting of *config.decoder_layers* layers. Each layer is a [`BartDecoderLayer`]\n",
        "\n",
        "    Args:\n",
        "        config: BartConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: BartConfig, embed_tokens: Optional[nn.Embedding] = None):\n",
        "        super().__init__(config)\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.decoder_layerdrop\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_target_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n",
        "\n",
        "        self.embed_tokens = nn.Embedding(config.vocab_size, config.d_model, self.padding_idx)\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens.weight = embed_tokens.weight\n",
        "\n",
        "        self.embed_positions = BartLearnedPositionalEmbedding(\n",
        "            config.max_position_embeddings,\n",
        "            config.d_model,\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BartDecoderLayer(config) for _ in range(config.decoder_layers)])\n",
        "        self.layernorm_embedding = nn.LayerNorm(config.d_model)\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    def _prepare_decoder_attention_mask(self, attention_mask, input_shape, inputs_embeds, past_key_values_length):\n",
        "        # create causal mask\n",
        "        # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "        combined_attention_mask = None\n",
        "        if input_shape[-1] > 1:\n",
        "            combined_attention_mask = _make_causal_mask(\n",
        "                input_shape,\n",
        "                inputs_embeds.dtype,\n",
        "                device=inputs_embeds.device,\n",
        "                past_key_values_length=past_key_values_length,\n",
        "            )\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            expanded_attn_mask = _expand_mask(attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1]).to(\n",
        "                inputs_embeds.device\n",
        "            )\n",
        "            combined_attention_mask = (\n",
        "                expanded_attn_mask if combined_attention_mask is None else expanded_attn_mask + combined_attention_mask\n",
        "            )\n",
        "\n",
        "        return combined_attention_mask\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, BaseModelOutputWithPastAndCrossAttentions]:\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n",
        "                provide it.\n",
        "\n",
        "                Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "                [`PreTrainedTokenizer.__call__`] for details.\n",
        "\n",
        "                [What are input IDs?](../glossary#input-ids)\n",
        "            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 for tokens that are **not masked**,\n",
        "                - 0 for tokens that are **masked**.\n",
        "\n",
        "                [What are attention masks?](../glossary#attention-mask)\n",
        "            encoder_hidden_states (`torch.FloatTensor` of shape `(batch_size, encoder_sequence_length, hidden_size)`, *optional*):\n",
        "                Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention\n",
        "                of the decoder.\n",
        "            encoder_attention_mask (`torch.LongTensor` of shape `(batch_size, encoder_sequence_length)`, *optional*):\n",
        "                Mask to avoid performing cross-attention on padding tokens indices of encoder input_ids. Mask values\n",
        "                selected in `[0, 1]`:\n",
        "\n",
        "                - 1 for tokens that are **not masked**,\n",
        "                - 0 for tokens that are **masked**.\n",
        "\n",
        "                [What are attention masks?](../glossary#attention-mask)\n",
        "            head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "                Mask to nullify selected heads of the attention modules. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 indicates the head is **not masked**,\n",
        "                - 0 indicates the head is **masked**.\n",
        "\n",
        "            cross_attn_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "                Mask to nullify selected heads of the cross-attention modules in the decoder to avoid performing\n",
        "                cross-attention on hidden heads. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 indicates the head is **not masked**,\n",
        "                - 0 indicates the head is **masked**.\n",
        "\n",
        "            past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
        "                Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of\n",
        "                shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of\n",
        "                shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`.\n",
        "\n",
        "                Contains pre-computed hidden-states (key and values in the self-attention blocks and in the\n",
        "                cross-attention blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n",
        "\n",
        "                If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those\n",
        "                that don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of\n",
        "                all `decoder_input_ids` of shape `(batch_size, sequence_length)`. inputs_embeds (`torch.FloatTensor` of\n",
        "                shape `(batch_size, sequence_length, hidden_size)`, *optional*): Optionally, instead of passing\n",
        "                `input_ids` you can choose to directly pass an embedded representation. This is useful if you want more\n",
        "                control over how to convert `input_ids` indices into associated vectors than the model's internal\n",
        "                embedding lookup matrix.\n",
        "            output_attentions (`bool`, *optional*):\n",
        "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "                returned tensors for more detail.\n",
        "            output_hidden_states (`bool`, *optional*):\n",
        "                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n",
        "                for more detail.\n",
        "            return_dict (`bool`, *optional*):\n",
        "                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
        "        \"\"\"\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input = input_ids\n",
        "            input_shape = input.shape\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "            input = inputs_embeds[:, :, -1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input) * self.embed_scale\n",
        "\n",
        "        attention_mask = self._prepare_decoder_attention_mask(\n",
        "            attention_mask, input_shape, inputs_embeds, past_key_values_length\n",
        "        )\n",
        "\n",
        "        # expand encoder attention mask\n",
        "        if encoder_hidden_states is not None and encoder_attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            encoder_attention_mask = _expand_mask(encoder_attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n",
        "\n",
        "        # embed positions\n",
        "        positions = self.embed_positions(input, past_key_values_length)\n",
        "        positions = positions.to(inputs_embeds.device)\n",
        "\n",
        "        hidden_states = inputs_embeds + positions\n",
        "        hidden_states = self.layernorm_embedding(hidden_states)\n",
        "\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        if self.gradient_checkpointing and self.training:\n",
        "            if use_cache:\n",
        "                logger.warning_once(\n",
        "                    \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                )\n",
        "                use_cache = False\n",
        "\n",
        "        # decoder layers\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attns = () if output_attentions else None\n",
        "        all_cross_attentions = () if (output_attentions and encoder_hidden_states is not None) else None\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "\n",
        "        # check if head_mask/cross_attn_head_mask has a correct number of layers specified if desired\n",
        "        for attn_mask, mask_name in zip([head_mask, cross_attn_head_mask], [\"head_mask\", \"cross_attn_head_mask\"]):\n",
        "            if attn_mask is not None:\n",
        "                if attn_mask.size()[0] != (len(self.layers)):\n",
        "                    raise ValueError(\n",
        "                        f\"The `{mask_name}` should be specified for {len(self.layers)} layers, but it is for\"\n",
        "                        f\" {head_mask.size()[0]}.\"\n",
        "                    )\n",
        "\n",
        "        for idx, decoder_layer in enumerate(self.layers):\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states += (hidden_states,)\n",
        "            if self.training:\n",
        "                dropout_probability = torch.rand([])\n",
        "                if dropout_probability < self.layerdrop:\n",
        "                    continue\n",
        "\n",
        "            past_key_value = past_key_values[idx] if past_key_values is not None else None\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        # None for past_key_value\n",
        "                        return module(*inputs, output_attentions, use_cache)\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(decoder_layer),\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    head_mask[idx] if head_mask is not None else None,\n",
        "                    cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None,\n",
        "                    None,\n",
        "                )\n",
        "            else:\n",
        "                layer_outputs = decoder_layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask=attention_mask,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    encoder_attention_mask=encoder_attention_mask,\n",
        "                    layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                    cross_attn_layer_head_mask=(\n",
        "                        cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None\n",
        "                    ),\n",
        "                    past_key_value=past_key_value,\n",
        "                    output_attentions=output_attentions,\n",
        "                    use_cache=use_cache,\n",
        "                )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[3 if output_attentions else 1],)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_self_attns += (layer_outputs[1],)\n",
        "\n",
        "                if encoder_hidden_states is not None:\n",
        "                    all_cross_attentions += (layer_outputs[2],)\n",
        "\n",
        "        # add hidden states from the last decoder layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states += (hidden_states,)\n",
        "\n",
        "        next_cache = next_decoder_cache if use_cache else None\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [hidden_states, next_cache, all_hidden_states, all_self_attns, all_cross_attentions]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attns,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "@add_start_docstrings(\n",
        "    \"The bare BART Model outputting raw hidden-states without any specific head on top.\",\n",
        "    BART_START_DOCSTRING,\n",
        ")\n",
        "class BartModel(BartPreTrainedModel):\n",
        "    _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\"]\n",
        "\n",
        "    def __init__(self, config: BartConfig):\n",
        "        super().__init__(config)\n",
        "\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "\n",
        "        self.encoder = BartEncoder(config, self.shared)\n",
        "        self.decoder = BartDecoder(config, self.shared)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.shared\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.shared = value\n",
        "        self.encoder.embed_tokens = self.shared\n",
        "        self.decoder.embed_tokens = self.shared\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.decoder\n",
        "\n",
        "    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n",
        "    @add_code_sample_docstrings(\n",
        "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
        "        output_type=Seq2SeqModelOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "        expected_output=_EXPECTED_OUTPUT_SHAPE,\n",
        "    )\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqModelOutput]:\n",
        "        # different to other models, Bart automatically creates decoder_input_ids from\n",
        "        # input_ids if no decoder_input_ids are provided\n",
        "        if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
        "            if input_ids is None:\n",
        "                raise ValueError(\n",
        "                    \"If no `decoder_input_ids` or `decoder_inputs_embeds` are \"\n",
        "                    \"passed, `input_ids` cannot be `None`. Please pass either \"\n",
        "                    \"`input_ids` or `decoder_input_ids` or `decoder_inputs_embeds`.\"\n",
        "                )\n",
        "\n",
        "            decoder_input_ids = shift_tokens_right(\n",
        "                input_ids, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "            )\n",
        "\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0],\n",
        "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
        "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
        "            )\n",
        "\n",
        "        # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            encoder_hidden_states=encoder_outputs[0],\n",
        "            encoder_attention_mask=attention_mask,\n",
        "            head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return decoder_outputs + encoder_outputs\n",
        "\n",
        "        return Seq2SeqModelOutput(\n",
        "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
        "            past_key_values=decoder_outputs.past_key_values,\n",
        "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
        "            decoder_attentions=decoder_outputs.attentions,\n",
        "            cross_attentions=decoder_outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
        "            encoder_attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "@add_start_docstrings(\n",
        "    \"The BART Model with a language modeling head. Can be used for summarization.\", BART_START_DOCSTRING\n",
        ")\n",
        "class BartForConditionalGeneration(BartPreTrainedModel):\n",
        "    base_model_prefix = \"model\"\n",
        "    _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\", \"lm_head.weight\"]\n",
        "    _keys_to_ignore_on_load_missing = [\"final_logits_bias\"]\n",
        "\n",
        "    def __init__(self, config: BartConfig):\n",
        "        super().__init__(config)\n",
        "        self.model = BartModel(config)\n",
        "        self.register_buffer(\"final_logits_bias\", torch.zeros((1, self.model.shared.num_embeddings)))\n",
        "        self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.model.get_encoder()\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.get_decoder()\n",
        "\n",
        "    def resize_token_embeddings(self, new_num_tokens: int, pad_to_multiple_of: Optional[int] = None) -> nn.Embedding:\n",
        "        new_embeddings = super().resize_token_embeddings(new_num_tokens, pad_to_multiple_of)\n",
        "        self._resize_final_logits_bias(new_embeddings.weight.shape[0])\n",
        "        return new_embeddings\n",
        "\n",
        "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
        "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
        "        if new_num_tokens <= old_num_tokens:\n",
        "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
        "        else:\n",
        "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
        "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
        "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n",
        "    @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n",
        "    @add_end_docstrings(BART_GENERATION_EXAMPLE)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqLMOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "            Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
        "            config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
        "            (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
        "\n",
        "        Returns:\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if labels is not None:\n",
        "            if use_cache:\n",
        "                logger.warning(\"The `use_cache` argument is changed to `False` since `labels` is provided.\")\n",
        "            use_cache = False\n",
        "            if decoder_input_ids is None and decoder_inputs_embeds is None:\n",
        "                decoder_input_ids = shift_tokens_right(\n",
        "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "                )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        lm_logits = self.lm_head(outputs[0])\n",
        "        lm_logits = lm_logits + self.final_logits_bias.to(lm_logits.device)\n",
        "\n",
        "        masked_lm_loss = None\n",
        "        if labels is not None:\n",
        "            labels = labels.to(lm_logits.device)\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + outputs[1:]\n",
        "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
        "\n",
        "        return Seq2SeqLMOutput(\n",
        "            loss=masked_lm_loss,\n",
        "            logits=lm_logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
        "            decoder_attentions=outputs.decoder_attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
        "            encoder_attentions=outputs.encoder_attentions,\n",
        "        )\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        decoder_input_ids,\n",
        "        past_key_values=None,\n",
        "        attention_mask=None,\n",
        "        decoder_attention_mask=None,\n",
        "        head_mask=None,\n",
        "        decoder_head_mask=None,\n",
        "        cross_attn_head_mask=None,\n",
        "        use_cache=None,\n",
        "        encoder_outputs=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # cut decoder_input_ids if past_key_values is used\n",
        "        if past_key_values is not None:\n",
        "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "            \"past_key_values\": past_key_values,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"decoder_attention_mask\": decoder_attention_mask,\n",
        "            \"head_mask\": head_mask,\n",
        "            \"decoder_head_mask\": decoder_head_mask,\n",
        "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
        "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
        "        }\n",
        "\n",
        "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
        "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
        "\n",
        "    @staticmethod\n",
        "    def _reorder_cache(past_key_values, beam_idx):\n",
        "        reordered_past = ()\n",
        "        for layer_past in past_key_values:\n",
        "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
        "            reordered_past += (\n",
        "                tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past[:2])\n",
        "                + layer_past[2:],\n",
        "            )\n",
        "        return reordered_past\n",
        "\n",
        "\n",
        "@add_start_docstrings(\n",
        "    \"\"\"\n",
        "    Bart model with a sequence classification/head on top (a linear layer on top of the pooled output) e.g. for GLUE\n",
        "    tasks.\n",
        "    \"\"\",\n",
        "    BART_START_DOCSTRING,\n",
        ")\n",
        "class BartForSequenceClassification(BartPreTrainedModel):\n",
        "    _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\"]\n",
        "\n",
        "    def __init__(self, config: BartConfig, **kwargs):\n",
        "        super().__init__(config, **kwargs)\n",
        "        self.model = BartModel(config)\n",
        "        self.classification_head = BartClassificationHead(\n",
        "            config.d_model,\n",
        "            config.d_model,\n",
        "            config.num_labels,\n",
        "            config.classifier_dropout,\n",
        "        )\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n",
        "    @add_code_sample_docstrings(\n",
        "        checkpoint=_CHECKPOINT_FOR_SEQUENCE_CLASSIFICATION,\n",
        "        output_type=Seq2SeqSequenceClassifierOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "        expected_output=_SEQ_CLASS_EXPECTED_OUTPUT,\n",
        "        expected_loss=_SEQ_CLASS_EXPECTED_LOSS,\n",
        "    )\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqSequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        if labels is not None:\n",
        "            use_cache = False\n",
        "\n",
        "        if input_ids is None and inputs_embeds is not None:\n",
        "            raise NotImplementedError(\n",
        "                f\"Passing input embeddings is currently not supported for {self.__class__.__name__}\"\n",
        "            )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        hidden_states = outputs[0]  # last hidden state\n",
        "\n",
        "        eos_mask = input_ids.eq(self.config.eos_token_id).to(hidden_states.device)\n",
        "\n",
        "        if len(torch.unique_consecutive(eos_mask.sum(1))) > 1:\n",
        "            raise ValueError(\"All examples must have the same number of <eos> tokens.\")\n",
        "        sentence_representation = hidden_states[eos_mask, :].view(hidden_states.size(0), -1, hidden_states.size(-1))[\n",
        "            :, -1, :\n",
        "        ]\n",
        "        logits = self.classification_head(sentence_representation)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            labels = labels.to(logits.device)\n",
        "            if self.config.problem_type is None:\n",
        "                if self.config.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.config.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.config.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return Seq2SeqSequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
        "            decoder_attentions=outputs.decoder_attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
        "            encoder_attentions=outputs.encoder_attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "@add_start_docstrings(\n",
        "    \"\"\"\n",
        "    BART Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\n",
        "    layer on top of the hidden-states output to compute `span start logits` and `span end logits`).\n",
        "    \"\"\",\n",
        "    BART_START_DOCSTRING,\n",
        ")\n",
        "class BartForQuestionAnswering(BartPreTrainedModel):\n",
        "    _tied_weights_keys = [\"encoder.embed_tokens.weight\", \"decoder.embed_tokens.weight\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        config.num_labels = 2\n",
        "        self.num_labels = config.num_labels\n",
        "\n",
        "        self.model = BartModel(config)\n",
        "        self.qa_outputs = nn.Linear(config.hidden_size, config.num_labels)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    @add_start_docstrings_to_model_forward(BART_INPUTS_DOCSTRING)\n",
        "    @add_code_sample_docstrings(\n",
        "        checkpoint=_CHECKPOINT_FOR_QA,\n",
        "        output_type=Seq2SeqQuestionAnsweringModelOutput,\n",
        "        config_class=_CONFIG_FOR_DOC,\n",
        "        expected_loss=_QA_EXPECTED_LOSS,\n",
        "        expected_output=_QA_EXPECTED_OUTPUT,\n",
        "    )\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.Tensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[List[torch.FloatTensor]] = None,\n",
        "        start_positions: Optional[torch.LongTensor] = None,\n",
        "        end_positions: Optional[torch.LongTensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, Seq2SeqQuestionAnsweringModelOutput]:\n",
        "        r\"\"\"\n",
        "        start_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (*sequence_length*). Position outside of the sequence\n",
        "            are not taken into account for computing the loss.\n",
        "        end_positions (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n",
        "            Positions are clamped to the length of the sequence (*sequence_length*). Position outside of the sequence\n",
        "            are not taken into account for computing the loss.\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            use_cache = False\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        sequence_output = outputs[0]\n",
        "\n",
        "        logits = self.qa_outputs(sequence_output)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "        start_logits = start_logits.squeeze(-1).contiguous()\n",
        "        end_logits = end_logits.squeeze(-1).contiguous()\n",
        "\n",
        "        total_loss = None\n",
        "        if start_positions is not None and end_positions is not None:\n",
        "            # If we are on multi-GPU, split add a dimension\n",
        "            if len(start_positions.size()) > 1:\n",
        "                start_positions = start_positions.squeeze(-1)\n",
        "            if len(end_positions.size()) > 1:\n",
        "                end_positions = end_positions.squeeze(-1)\n",
        "            # sometimes the start/end positions are outside our model inputs, we ignore these terms\n",
        "            ignored_index = start_logits.size(1)\n",
        "            start_positions = start_positions.clamp(0, ignored_index)\n",
        "            end_positions = end_positions.clamp(0, ignored_index)\n",
        "\n",
        "            loss_fct = CrossEntropyLoss(ignore_index=ignored_index)\n",
        "            start_loss = loss_fct(start_logits, start_positions)\n",
        "            end_loss = loss_fct(end_logits, end_positions)\n",
        "            total_loss = (start_loss + end_loss) / 2\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (\n",
        "                start_logits,\n",
        "                end_logits,\n",
        "            ) + outputs[1:]\n",
        "            return ((total_loss,) + output) if total_loss is not None else output\n",
        "\n",
        "        return Seq2SeqQuestionAnsweringModelOutput(\n",
        "            loss=total_loss,\n",
        "            start_logits=start_logits,\n",
        "            end_logits=end_logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
        "            decoder_attentions=outputs.decoder_attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
        "            encoder_attentions=outputs.encoder_attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "class BartDecoderWrapper(BartPreTrainedModel):\n",
        "    \"\"\"\n",
        "    This wrapper class is a helper class to correctly load pretrained checkpoints when the causal language model is\n",
        "    used in combination with the [`EncoderDecoderModel`] framework.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.decoder = BartDecoder(config)\n",
        "\n",
        "    def forward(self, *args, **kwargs):\n",
        "        return self.decoder(*args, **kwargs)\n",
        "\n",
        "\n",
        "@add_start_docstrings(\n",
        "    \"\"\"\n",
        "    BART decoder with with a language modeling head on top (linear layer with weights tied to the input embeddings).\n",
        "    \"\"\",\n",
        "    BART_START_DOCSTRING,\n",
        ")\n",
        "class BartForCausalLM(BartPreTrainedModel):\n",
        "    _tied_weights_keys = [\"lm_head.weight\"]\n",
        "\n",
        "    def __init__(self, config):\n",
        "        config = copy.deepcopy(config)\n",
        "        config.is_decoder = True\n",
        "        config.is_encoder_decoder = False\n",
        "        super().__init__(config)\n",
        "        self.model = BartDecoderWrapper(config)\n",
        "\n",
        "        self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.model.decoder.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.model.decoder.embed_tokens = value\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    def set_decoder(self, decoder):\n",
        "        self.model.decoder = decoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.decoder\n",
        "\n",
        "    @replace_return_docstrings(output_type=CausalLMOutputWithCrossAttentions, config_class=_CONFIG_FOR_DOC)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, CausalLMOutputWithCrossAttentions]:\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
        "                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n",
        "                provide it.\n",
        "\n",
        "                Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
        "                [`PreTrainedTokenizer.__call__`] for details.\n",
        "\n",
        "                [What are input IDs?](../glossary#input-ids)\n",
        "            attention_mask (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 for tokens that are **not masked**,\n",
        "                - 0 for tokens that are **masked**.\n",
        "\n",
        "                [What are attention masks?](../glossary#attention-mask)\n",
        "            encoder_hidden_states  (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
        "                Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention\n",
        "                if the model is configured as a decoder.\n",
        "            encoder_attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used\n",
        "                in the cross-attention if the model is configured as a decoder. Mask values selected in `[0, 1]`:\n",
        "            head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "                Mask to nullify selected heads of the attention modules. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 indicates the head is **not masked**,\n",
        "                - 0 indicates the head is **masked**.\n",
        "\n",
        "            cross_attn_head_mask (`torch.Tensor` of shape `(decoder_layers, decoder_attention_heads)`, *optional*):\n",
        "                Mask to nullify selected heads of the cross-attention modules. Mask values selected in `[0, 1]`:\n",
        "\n",
        "                - 1 indicates the head is **not masked**,\n",
        "                - 0 indicates the head is **masked**.\n",
        "\n",
        "            past_key_values (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `use_cache=True` is passed or when `config.use_cache=True`):\n",
        "                Tuple of `tuple(torch.FloatTensor)` of length `config.n_layers`, with each tuple having 2 tensors of\n",
        "                shape `(batch_size, num_heads, sequence_length, embed_size_per_head)`) and 2 additional tensors of\n",
        "                shape `(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)`. The two additional\n",
        "                tensors are only required when the model is used as a decoder in a Sequence to Sequence model.\n",
        "\n",
        "                Contains pre-computed hidden-states (key and values in the self-attention blocks and in the\n",
        "                cross-attention blocks) that can be used (see `past_key_values` input) to speed up sequential decoding.\n",
        "\n",
        "                If `past_key_values` are used, the user can optionally input only the last `decoder_input_ids` (those\n",
        "                that don't have their past key value states given to this model) of shape `(batch_size, 1)` instead of\n",
        "                all `decoder_input_ids` of shape `(batch_size, sequence_length)`.\n",
        "            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
        "                Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n",
        "                config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored\n",
        "                (masked), the loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`.\n",
        "            use_cache (`bool`, *optional*):\n",
        "                If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding\n",
        "                (see `past_key_values`).\n",
        "\n",
        "                - 1 for tokens that are **not masked**,\n",
        "                - 0 for tokens that are **masked**.\n",
        "            output_attentions (`bool`, *optional*):\n",
        "                Whether or not to return the attentions tensors of all attention layers. See `attentions` under\n",
        "                returned tensors for more detail.\n",
        "            output_hidden_states (`bool`, *optional*):\n",
        "                Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors\n",
        "                for more detail.\n",
        "            return_dict (`bool`, *optional*):\n",
        "                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
        "\n",
        "        Returns:\n",
        "\n",
        "        Example:\n",
        "\n",
        "        ```python\n",
        "        >>> from transformers import AutoTokenizer, BartForCausalLM\n",
        "\n",
        "        >>> tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "        >>> model = BartForCausalLM.from_pretrained(\"facebook/bart-base\", add_cross_attention=False)\n",
        "        >>> assert model.config.is_decoder, f\"{model.__class__} has to be configured as a decoder.\"\n",
        "        >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "        >>> outputs = model(**inputs)\n",
        "\n",
        "        >>> logits = outputs.logits\n",
        "        >>> expected_shape = [1, inputs.input_ids.shape[-1], model.config.vocab_size]\n",
        "        >>> list(logits.shape) == expected_shape\n",
        "        True\n",
        "        ```\"\"\"\n",
        "\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
        "        outputs = self.model.decoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        logits = self.lm_head(outputs[0])\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            labels = labels.to(logits.device)\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.config.vocab_size), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return (loss,) + output if loss is not None else output\n",
        "\n",
        "        return CausalLMOutputWithCrossAttentions(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "        )\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self, input_ids, past_key_values=None, attention_mask=None, use_cache=None, **kwargs\n",
        "    ):\n",
        "        # if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly\n",
        "        if attention_mask is None:\n",
        "            attention_mask = input_ids.new_ones(input_ids.shape)\n",
        "\n",
        "        if past_key_values:\n",
        "            input_ids = input_ids[:, -1:]\n",
        "        # first step, decoder_cached_states are empty\n",
        "        return {\n",
        "            \"input_ids\": input_ids,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"past_key_values\": past_key_values,\n",
        "            \"use_cache\": use_cache,\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def _reorder_cache(past_key_values, beam_idx):\n",
        "        reordered_past = ()\n",
        "        for layer_past in past_key_values:\n",
        "            reordered_past += (\n",
        "                tuple(past_state.index_select(0, beam_idx.to(past_state.device)) for past_state in layer_past),\n",
        "            )\n",
        "        return reordered_past"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:07.870821Z",
          "iopub.execute_input": "2023-10-25T07:08:07.871242Z",
          "iopub.status.idle": "2023-10-25T07:08:08.120633Z",
          "shell.execute_reply.started": "2023-10-25T07:08:07.871185Z",
          "shell.execute_reply": "2023-10-25T07:08:08.119438Z"
        },
        "trusted": true,
        "id": "HTquMOOP0lS5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")"
      ],
      "metadata": {
        "id": "TlqNaB8jIrJW",
        "outputId": "5fb99e49-3fca-4209-b21a-eae48f47651e",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:08.122073Z",
          "iopub.execute_input": "2023-10-25T07:08:08.122752Z",
          "iopub.status.idle": "2023-10-25T07:08:11.390207Z",
          "shell.execute_reply.started": "2023-10-25T07:08:08.122714Z",
          "shell.execute_reply": "2023-10-25T07:08:11.389196Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "255909783c654084a3aaaacea9efb260",
            "c7e8185ee8ac42e2b83e2316122c0adb",
            "501c11488082447cac97b3b951e49c5f",
            "81cde7b7fe444fb7bb61f0e6ff58f07d",
            "0cecda7e58de44aaa0edf5e6a892f1d7",
            "39356132e838438c9991ba4ba6694547",
            "c3cce9c52161433b97367c606cbe2ff4",
            "ae5879c9b63b47d89e9bdcc835071fad",
            "9d92633344854a639c0876ad98e4097f",
            "c0899606e84f4e03b7d2f1c06fda7305",
            "3f6075689d364cdf887e12d7f597e21b",
            "4f26b514830d47498b7fd83278e49953",
            "c4e127f40ca946f48d2d716d5037ac45",
            "34289f0a3313410481448fd01df18ef4",
            "03c27fd713e54bcfb453437a20f7f047",
            "2735b1e2608841269ce1b7d7edd0de3d",
            "473f79de63cb404ea27be020bbaaad94",
            "ce7a82b0112b41f99343bbf7c5198dc6",
            "ab50a1d6debe4baca7cb42ce884ca087",
            "91d96bb3471b4f1db84d6afd2bb02a57",
            "55376d7853db425d95352ea78cde9a4a",
            "08d958527fdd4de8b71727a6f6406eb1"
          ]
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "255909783c654084a3aaaacea9efb260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f26b514830d47498b7fd83278e49953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['decoder.layers.4.encoder_attn.reatten_matrix', 'decoder.layers.2.self_attn.reatten_matrix', 'encoder.layers.10.self_attn.reatten_matrix', 'encoder.layers.1.self_attn.reatten_matrix', 'decoder.layers.6.self_attn.reatten_matrix', 'decoder.layers.5.self_attn.reatten_matrix', 'decoder.layers.2.encoder_attn.reatten_matrix', 'encoder.layers.8.self_attn.reatten_matrix', 'encoder.layers.4.self_attn.reatten_matrix', 'encoder.layers.3.self_attn.reatten_matrix', 'encoder.layers.9.self_attn.reatten_matrix', 'encoder.layers.11.self_attn.reatten_matrix', 'decoder.layers.7.self_attn.reatten_matrix', 'decoder.layers.10.self_attn.reatten_matrix', 'decoder.layers.0.encoder_attn.reatten_matrix', 'encoder.layers.5.self_attn.reatten_matrix', 'decoder.layers.10.encoder_attn.reatten_matrix', 'decoder.layers.11.self_attn.reatten_matrix', 'encoder.layers.0.self_attn.reatten_matrix', 'decoder.layers.1.self_attn.reatten_matrix', 'encoder.layers.6.self_attn.reatten_matrix', 'decoder.layers.0.self_attn.reatten_matrix', 'decoder.layers.5.encoder_attn.reatten_matrix', 'decoder.layers.11.encoder_attn.reatten_matrix', 'encoder.layers.2.self_attn.reatten_matrix', 'decoder.layers.1.encoder_attn.reatten_matrix', 'decoder.layers.4.self_attn.reatten_matrix', 'decoder.layers.9.encoder_attn.reatten_matrix', 'decoder.layers.3.self_attn.reatten_matrix', 'decoder.layers.8.encoder_attn.reatten_matrix', 'decoder.layers.8.self_attn.reatten_matrix', 'decoder.layers.6.encoder_attn.reatten_matrix', 'decoder.layers.9.self_attn.reatten_matrix', 'decoder.layers.7.encoder_attn.reatten_matrix', 'decoder.layers.3.encoder_attn.reatten_matrix', 'encoder.layers.7.self_attn.reatten_matrix']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that  we don't get a warning like in our classification example. This means we used all the weights of the pretrained model and there is no randomly initialized head in this case."
      ],
      "metadata": {
        "id": "CczA5lJlIrJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To instantiate a `Seq2SeqTrainer`, we will need to define three more things. The most important is the [`Seq2SeqTrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
      ],
      "metadata": {
        "id": "_N8urzhyIrJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-re-attention-mini-seq-512\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "#     push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ie_CLhlEiIFq",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:11.391816Z",
          "iopub.execute_input": "2023-10-25T07:08:11.392115Z",
          "iopub.status.idle": "2023-10-25T07:08:11.406434Z",
          "shell.execute_reply.started": "2023-10-25T07:08:11.392088Z",
          "shell.execute_reply": "2023-10-25T07:08:11.405121Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the cell and customize the weight decay. Since the `Seq2SeqTrainer` will save the model regularly and our dataset is quite large, we tell it to make three saves maximum. Lastly, we use the `predict_with_generate` option (to properly generate summaries) and activate mixed precision training (to go a bit faster).\n",
        "\n",
        "The last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/t5-finetuned-xsum\"` or `\"huggingface/t5-finetuned-xsum\"`).\n",
        "\n",
        "Then, we need a special kind of data collator, which will not only pad the inputs to the maximum length in the batch, but also the labels:"
      ],
      "metadata": {
        "id": "km3pGVdTIrJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "lP7bL6M3iIFr",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:11.407639Z",
          "iopub.execute_input": "2023-10-25T07:08:11.407959Z",
          "iopub.status.idle": "2023-10-25T07:08:11.415572Z",
          "shell.execute_reply.started": "2023-10-25T07:08:11.407934Z",
          "shell.execute_reply": "2023-10-25T07:08:11.414633Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
      ],
      "metadata": {
        "id": "7sZOdRlRIrJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    # Note that other metrics may not have a `use_aggregator` parameter\n",
        "    # and thus will return a list, computing a metric for each sentence.\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "UmvbnJ9JIrJd",
        "outputId": "0fcaaea7-906c-4293-f2bc-e59486805825",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:11.416803Z",
          "iopub.execute_input": "2023-10-25T07:08:11.417525Z",
          "iopub.status.idle": "2023-10-25T07:08:11.431551Z",
          "shell.execute_reply.started": "2023-10-25T07:08:11.417486Z",
          "shell.execute_reply": "2023-10-25T07:08:11.430537Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.python.sh | bash"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:11.432776Z",
          "iopub.execute_input": "2023-10-25T07:08:11.433115Z",
          "iopub.status.idle": "2023-10-25T07:08:13.065981Z",
          "shell.execute_reply.started": "2023-10-25T07:08:11.433084Z",
          "shell.execute_reply": "2023-10-25T07:08:13.064828Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kd3r-ly0lTF",
        "outputId": "80a560fb-6059-4e19-9c23-f75c6f04f28f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for curl...\n",
            "Detected curl...\n",
            "Detected VirtualEnv: Please visit https://packagecloud.io/github/git-lfs/install#virtualenv\n",
            "pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "No pip.conf found, creating\n",
            "The repository is setup! You can now install packages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git-lfs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:13.068003Z",
          "iopub.execute_input": "2023-10-25T07:08:13.068515Z",
          "iopub.status.idle": "2023-10-25T07:08:15.514938Z",
          "shell.execute_reply.started": "2023-10-25T07:08:13.068461Z",
          "shell.execute_reply": "2023-10-25T07:08:15.513777Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9w7e6mI0lTF",
        "outputId": "b13fe2a7-e740-4d58-99cf-0bb932439b3e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
      ],
      "metadata": {
        "id": "rXuFTAzDIrJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "imY1oC3SIrJf",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:08:15.516966Z",
          "iopub.execute_input": "2023-10-25T07:08:15.517450Z",
          "iopub.status.idle": "2023-10-25T07:08:15.688397Z",
          "shell.execute_reply.started": "2023-10-25T07:08:15.517409Z",
          "shell.execute_reply": "2023-10-25T07:08:15.687287Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ],
      "metadata": {
        "id": "CdzABDVcIrJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    trainer.train()\n",
        "#     trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:44:18.042489Z",
          "iopub.execute_input": "2023-10-25T07:44:18.043566Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e9c947b-8756-4739-859f-e7f61f008c4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.121940</td>\n",
              "      <td>9.536500</td>\n",
              "      <td>1.590500</td>\n",
              "      <td>7.738700</td>\n",
              "      <td>9.464000</td>\n",
              "      <td>16.480000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.918040</td>\n",
              "      <td>14.693600</td>\n",
              "      <td>5.283000</td>\n",
              "      <td>12.051400</td>\n",
              "      <td>14.432400</td>\n",
              "      <td>19.540000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.417598</td>\n",
              "      <td>14.120200</td>\n",
              "      <td>6.625600</td>\n",
              "      <td>11.920400</td>\n",
              "      <td>13.670000</td>\n",
              "      <td>19.550000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.108607</td>\n",
              "      <td>14.229800</td>\n",
              "      <td>6.191400</td>\n",
              "      <td>12.045800</td>\n",
              "      <td>13.331200</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.888240</td>\n",
              "      <td>14.151700</td>\n",
              "      <td>5.370200</td>\n",
              "      <td>11.785300</td>\n",
              "      <td>13.752100</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.721608</td>\n",
              "      <td>14.986300</td>\n",
              "      <td>6.088700</td>\n",
              "      <td>12.355500</td>\n",
              "      <td>14.610900</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.567553</td>\n",
              "      <td>14.975300</td>\n",
              "      <td>5.552500</td>\n",
              "      <td>12.097400</td>\n",
              "      <td>14.718700</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.440213</td>\n",
              "      <td>14.782500</td>\n",
              "      <td>5.971900</td>\n",
              "      <td>12.409700</td>\n",
              "      <td>14.545800</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.336091</td>\n",
              "      <td>15.892400</td>\n",
              "      <td>6.408900</td>\n",
              "      <td>12.648000</td>\n",
              "      <td>15.487000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.240717</td>\n",
              "      <td>16.166600</td>\n",
              "      <td>5.993600</td>\n",
              "      <td>13.126400</td>\n",
              "      <td>15.661700</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.151912</td>\n",
              "      <td>15.893900</td>\n",
              "      <td>6.446500</td>\n",
              "      <td>12.808800</td>\n",
              "      <td>15.417500</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.055221</td>\n",
              "      <td>16.160100</td>\n",
              "      <td>6.241600</td>\n",
              "      <td>12.975500</td>\n",
              "      <td>15.777300</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='106' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [106/125 01:02 < 00:11, 1.66 it/s, Epoch 0.84/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-acecf97cec28>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#     trainer.push_to_hub()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2734\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1989\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 198.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 152.81 MiB is free. Process 2185 has 14.60 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 632.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "GNAvTDPSaW1H",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:31:24.630579Z",
          "iopub.execute_input": "2023-10-25T07:31:24.630970Z",
          "iopub.status.idle": "2023-10-25T07:31:24.658370Z",
          "shell.execute_reply.started": "2023-10-25T07:31:24.630924Z",
          "shell.execute_reply": "2023-10-25T07:31:24.657277Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_before_finetuned = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "qGwajSFvp13X",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:31:24.659817Z",
          "iopub.execute_input": "2023-10-25T07:31:24.660183Z",
          "iopub.status.idle": "2023-10-25T07:31:35.450059Z",
          "shell.execute_reply.started": "2023-10-25T07:31:24.660148Z",
          "shell.execute_reply": "2023-10-25T07:31:35.448767Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(test_samples, model):\n",
        "    inputs = tokenizer(\n",
        "        test_samples[\"question\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    input_ids = inputs.input_ids.to(model.device)\n",
        "    attention_mask = inputs.attention_mask.to(model.device)\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_new_tokens=512)\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return outputs, output_str"
      ],
      "metadata": {
        "id": "oSce-pEPZ0Jq",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:31:35.451907Z",
          "iopub.execute_input": "2023-10-25T07:31:35.452641Z",
          "iopub.status.idle": "2023-10-25T07:31:35.461715Z",
          "shell.execute_reply.started": "2023-10-25T07:31:35.452599Z",
          "shell.execute_reply": "2023-10-25T07:31:35.460635Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = vals_ds.select(range(8))\n",
        "\n",
        "\n",
        "summaries_before_tuning = generate_summary(test_samples, model_before_finetuned)[1]\n",
        "summaries_after_tuning = generate_summary(test_samples, model)[1]"
      ],
      "metadata": {
        "id": "OX4PJRRCZ5Wl",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:31:35.463320Z",
          "iopub.execute_input": "2023-10-25T07:31:35.463653Z",
          "iopub.status.idle": "2023-10-25T07:34:40.088950Z",
          "shell.execute_reply.started": "2023-10-25T07:31:35.463621Z",
          "shell.execute_reply": "2023-10-25T07:34:40.087878Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    tabulate(\n",
        "        zip(\n",
        "            range(len(summaries_after_tuning)),\n",
        "            summaries_after_tuning,\n",
        "            summaries_before_tuning,\n",
        "        ),\n",
        "        headers=[\"Id\", \"Answer after\", \"Answer before\"],\n",
        "    )\n",
        ")\n",
        "print(\"\\nTarget answers:\\n\")\n",
        "print(\n",
        "    tabulate(list(enumerate(test_samples[\"answer\"])), headers=[\"Id\", \"Target answer\"])\n",
        ")\n",
        "print(\"\\nSource questions:\\n\")\n",
        "print(tabulate(list(enumerate(test_samples[\"question\"])), headers=[\"Id\", \"Question\"]))"
      ],
      "metadata": {
        "id": "ghUn2o8jaRSm",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:34:40.090469Z",
          "iopub.execute_input": "2023-10-25T07:34:40.090820Z",
          "iopub.status.idle": "2023-10-25T07:34:40.138406Z",
          "shell.execute_reply.started": "2023-10-25T07:34:40.090787Z",
          "shell.execute_reply": "2023-10-25T07:34:40.137373Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries_after_tuning"
      ],
      "metadata": {
        "id": "iVEDsRW6sc_j",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:34:40.140075Z",
          "iopub.execute_input": "2023-10-25T07:34:40.140490Z",
          "iopub.status.idle": "2023-10-25T07:34:40.149924Z",
          "shell.execute_reply.started": "2023-10-25T07:34:40.140456Z",
          "shell.execute_reply": "2023-10-25T07:34:40.148961Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(enumerate(test_samples[\"answer\"]))"
      ],
      "metadata": {
        "id": "NJVLQqcvuZBx",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:34:40.151145Z",
          "iopub.execute_input": "2023-10-25T07:34:40.151509Z",
          "iopub.status.idle": "2023-10-25T07:34:40.161783Z",
          "shell.execute_reply.started": "2023-10-25T07:34:40.151484Z",
          "shell.execute_reply": "2023-10-25T07:34:40.160690Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import pipeline, Conversation\n",
        "\n",
        "# chatbot = pipeline(\"conversational\", model=model, tokenizer=tokenizer)\n",
        "# conversation = Conversation(\"hello am 22 years old and i have type 2diabet i wanted to sign for a new gym which use electric vibes to improve heart pulses and fasten the process of loosing weight i wanted to know if it is dangerous for me knowing that 20min of this sports equals 4 h of normal one thanks\t\")\n",
        "# conversation = chatbot(conversation)\n",
        "# conversation.generated_responses[-1]"
      ],
      "metadata": {
        "id": "ImT5drFr5fzw",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:34:40.163938Z",
          "iopub.execute_input": "2023-10-25T07:34:40.164616Z",
          "iopub.status.idle": "2023-10-25T07:34:40.171299Z",
          "shell.execute_reply.started": "2023-10-25T07:34:40.164579Z",
          "shell.execute_reply": "2023-10-25T07:34:40.170154Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now upload the result of the training to the Hub, just execute this instruction:"
      ],
      "metadata": {
        "id": "b5rItmHxiIFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "NPyW6RDjiIFs",
        "execution": {
          "iopub.status.busy": "2023-10-25T07:34:40.172517Z",
          "iopub.execute_input": "2023-10-25T07:34:40.172766Z",
          "iopub.status.idle": "2023-10-25T07:35:16.475983Z",
          "shell.execute_reply.started": "2023-10-25T07:34:40.172743Z",
          "shell.execute_reply": "2023-10-25T07:35:16.474757Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"sgugger/my-awesome-model\")\n",
        "```"
      ],
      "metadata": {
        "id": "xqle58ISiIFs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OnvVbSnOiIFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}