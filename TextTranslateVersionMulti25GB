{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TextTranslateVersionMulti25GB","provenance":[{"file_id":"1XM7uzo139s5BWHgcnTSasqbh4TyhsFSg","timestamp":1615695867506},{"file_id":"1oGXlUH5nZpY0DtvyD3aNF9BJ8PBZ7xvr","timestamp":1615606457247},{"file_id":"1twNetFPIoMKNy13z_URcoMnz3lM2UBEM","timestamp":1602893130525}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"60NlBzUY0p4v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957134589,"user_tz":-420,"elapsed":992,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"93426925-54f5-418f-844a-2d6ce05eb9d7"},"source":["from google.colab import drive\n","drive.mount(\"/content/data\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/data; to attempt to forcibly remount, call drive.mount(\"/content/data\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"FLVd7dMX0Juy"},"source":["import os\n","import numpy as np\n","import unicodedata\n","import tensorflow as tf\n","import re\n","import io\n","import time\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75tqDrq10Ju3"},"source":["path_data_file = \"/content/data/MyDrive/data/rus-eng/rus.txt\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WSaFZmpj0Ju4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1615957136667,"user_tz":-420,"elapsed":3048,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"36d8141f-7482-46cc-b289-6f80878eb309"},"source":["def unicode_to_ascii(w):\n","    return ''.join(unicodedata.normalize(\"NFD\", c) for c in w if unicodedata.category(c) != 'Mn')\n","\n","word = \"Оно там?\"\n","unicode_to_ascii(word)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Оно там?'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"LAnnLl-M0Ju5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1615957136668,"user_tz":-420,"elapsed":3041,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"4ef8ad8a-eb94-4148-daa8-2fb161ed9400"},"source":["def preprocess_word(w):\n","    w = unicode_to_ascii(w)\n","\n","    w = re.sub(r\"([.!?,])\", r\" \\1\", w)\n","    w = re.sub(r'[\" ]', \" \", w)\n","\n","    w = w.strip()\n","    return \"<start> %s <end>\" % w\n","\n","preprocess_word(word)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<start> Оно там ? <end>'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"EkQaxG1S0Ju5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957137249,"user_tz":-420,"elapsed":3613,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"0911ef1e-ad6e-4e53-a876-9d24aac70ca2"},"source":["def create_dataset(path, num_instance):\n","    lines = io.open(path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n","    return zip(*[[preprocess_word(w) for w in line.split(\"\\t\")[:2]] for line in lines[:num_instance]])\n","\n","a, b = create_dataset(path_data_file, 3)\n","a, b"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(('<start> Go . <end>', '<start> Go . <end>', '<start> Go . <end>'),\n"," ('<start> Марш ! <end>', '<start> Иди . <end>', '<start> Идите . <end>'))"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"kjMePHWa0Ju6"},"source":["def tokenize(texts):\n","    \"\"\"\n","\n","    :param texts: the text to tokenize\n","    :return: the tensors and tokenizer of the texts\n","    \"\"\"\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","    tokenizer.fit_on_texts(texts)\n","\n","    tensor = tokenizer.texts_to_sequences(texts)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\n","\n","    return tensor, tokenizer\n","\n","\n","def load_dataset(path, num_instance):\n","    tar, inp = create_dataset(path, num_instance)\n","\n","    tar_tensor, tar_tokenizer = tokenize(tar)\n","    inp_tensor, inp_tokenizer = tokenize(inp)\n","\n","    return tar_tensor, inp_tensor, tar_tokenizer, inp_tokenizer\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T9ogCsc30Ju6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957149336,"user_tz":-420,"elapsed":15687,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"b67d761a-05cd-47d6-dce8-ed657d3d80aa"},"source":["NUM_EXAMPLES = 150000\n","\n","tar_tensor, inp_tensor, tar_tokenizer, inp_tokenizer = load_dataset(path_data_file, NUM_EXAMPLES)\n","\n","max_len_tar = tar_tensor.shape[1]\n","max_len_inp = inp_tensor.shape[1]\n","\n","max_len_tar, max_len_inp"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12, 15)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"NqZbiAjg0Ju6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957149337,"user_tz":-420,"elapsed":15681,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"a33efa3c-c1a5-4367-aa01-76ddf8153534"},"source":["inp_tensor_train, inp_tensor_val, tar_tensor_train, tar_tensor_val = train_test_split(inp_tensor, tar_tensor)\n","\n","len(inp_tensor_train), len(inp_tensor_val)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(112500, 37500)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Cyv7lBVQ0Ju7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957149338,"user_tz":-420,"elapsed":15675,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"ac97819a-4ee3-4cfa-8ed8-6743c0511dff"},"source":["def print_convert(tokenizer, tensor):\n","    for t in tensor:\n","        if t != 0:\n","            print(\"%d\\t--->\\t%s\" % (t, tokenizer.index_word[t]))\n","\n","print_convert(inp_tokenizer, inp_tensor_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\t--->\t<start>\n","13\t--->\tчто\n","119\t--->\tсо\n","13957\t--->\tшляпой\n","5\t--->\t?\n","2\t--->\t<end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXfjRzOt0Ju7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957149727,"user_tz":-420,"elapsed":16056,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"5669f6e0-df89-4176-c2a0-2ab0ef043160"},"source":["BUFFER_SIZE = 10000\n","BATCH_SIZE = 64\n","\n","dataset = tf.data.Dataset.from_tensor_slices((inp_tensor_train, tar_tensor_train))\n","dataset = dataset.shuffle(BUFFER_SIZE).cache().batch(BATCH_SIZE, drop_remainder=True).prefetch(1)\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((64, 15), (64, 12)), types: (tf.int32, tf.int32)>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"VtpFWiDb0Ju7"},"source":["EMBEDDING_DIM = 256\n","ENC_UNITS = 1024\n","DEC_UNITS = 1024\n","\n","vocab_inp_size = len(inp_tokenizer.word_index) + 1\n","vocab_tar_size = len(tar_tokenizer.word_index) + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5c4PNmP0Ju8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957149728,"user_tz":-420,"elapsed":16044,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"196116ae-4217-46ee-8e66-47528c728b94"},"source":["for exam_inp, exam_tar in dataset.take(1):\n","    print(exam_inp.shape, exam_tar.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(64, 15) (64, 12)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aR2RZrnZ0Ju8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957151080,"user_tz":-420,"elapsed":17387,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"428700d6-119b-4953-96fe-c4e885436fc5"},"source":["class Encoder(tf.keras.Model):\n","    def get_config(self):\n","        pass\n","    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n","        self.batch_size = batch_size\n","        self.encoder_units = encoder_units\n","        super(Encoder, self).__init__()\n","        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.gru = tf.keras.layers.GRU(encoder_units, return_sequences=True, return_state=True,\n","                                       recurrent_initializer=\"glorot_uniform\")\n","\n","    def call(self, x, hidden, *args):\n","        x = self.embedding(x)\n","        output, state = self.gru(x, initial_state=hidden)\n","        return output, state\n","\n","    def initialize_hidden(self):\n","        return tf.zeros((self.batch_size, self.encoder_units))\n","\n","\n","exam_inp, exam_tar = next(iter(dataset))\n","encoder_test = Encoder(vocab_inp_size, EMBEDDING_DIM, ENC_UNITS, batch_size=BATCH_SIZE)\n","\n","init_hidden = encoder_test.initialize_hidden()\n","sample_output, sample_hidden = encoder_test(exam_inp, init_hidden)\n","\n","\"Encoder Output Shape: \", sample_output.shape, \"Encoder Hidden shape: \", sample_hidden.shape\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Encoder Output Shape: ',\n"," TensorShape([64, 15, 1024]),\n"," 'Encoder Hidden shape: ',\n"," TensorShape([64, 1024]))"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"FS7wiM7F0Ju8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957243768,"user_tz":-420,"elapsed":1129,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"9e5a8184-dae7-47ce-ce81-87785529ff03"},"source":["class LuongAttention(tf.keras.Model):\n","    def __init__(self, fc_units):\n","        super(LuongAttention, self).__init__()\n","        self.fc_units = fc_units\n","        self.fc1 = tf.keras.layers.Dense(fc_units)\n","        self.fc2 = tf.keras.layers.Dense(fc_units)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    # def call(self, query, values, *args):\n","    #     \"\"\"\n","\n","    #     :param query: The hidden from encoder (batch_size, enc_hidden)\n","    #     :param values: encoder output (batch_size, seq_len, enc_hidden)\n","    #     :param args:\n","    #     :return:\n","    #     \"\"\"\n","\n","    #     # query hidden state shape == (batch_size, hidden size)\n","    #     # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    #     # values shape == (batch_size, max_len, hidden size)\n","    #     # expand dim to broadcast addition along the time axis to calculate the score\n","    #     query_time_with_axis = tf.expand_dims(query, axis=1)\n","    #     # fc2 --> (batch_size, ..., units)\n","    #     # fc1 --> (batch_size, ..., units)\n","    #     # fc1 + fc2 --> (batch_size, ..., units)\n","    #     # V --> (batch_size, ..., 1) (score shape)\n","    #     # score = self.V(tf.tanh(self.fc2(query_time_with_axis) + self.fc1(values)))\n","    #     # print(\"Query\", tf.reshape(query_time_with_axis, shape=(query_time_with_axis.shape[0], -1, )), self.fc1(values).shape)\n","    #     score = tf.matmul(query_time_with_axis, self.fc(values), transpose_b=True)\n","    #     # score = tf.expand_dims(score, axis=1)\n","    #     score = tf.squeeze(score, [1])\n","    #     # score = tf.transpose(score, [0, 2, 1])\n","    #     # print(\"Query\", score.shape)        \n","    #     # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","    #     attention_weights = tf.nn.softmax(score, axis=1)\n","    #     # Point wise element multi (not dot product)\n","    #     # context_vector = tf.reduce_sum(azttention_weights. * values, axis=1)\n","    #     context_vector = tf.reduce_sum(tf.expand_dims(attention_weights, axis=-1) * values, axis=1)\n","    #     context_vector = tf.reduce_sum(tf.matmul(attention_weights, values), axis=1)\n","    #     # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","\n","    #     return context_vector, attention_weights  \n","\n","    # def call(self, query, values, *args):\n","    #     \"\"\"\n","\n","    #     :param query: The hidden from encoder (batch_size, enc_hidden)\n","    #     :param values: encoder output (batch_size, seq_len, enc_hidden)\n","    #     :param args:\n","    #     :return:\n","    #     \"\"\"\n","\n","    #     # query hidden state shape == (batch_size, hidden size)\n","    #     # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    #     # values shape == (batch_size, max_len, hidden size)\n","    #     # expand dim to broadcast addition along the time axis to calculate the score\n","    #     query_time_with_axis = tf.expand_dims(query, axis=1)\n","    #     # fc2 --> (batch_size, ..., units)\n","    #     # fc1 --> (batch_size, ..., units)\n","    #     # fc1 + fc2 --> (batch_size, ..., units)\n","    #     # V --> (batch_size, ..., 1) (score shape)\n","    #     # score = self.V(tf.tanh(self.fc2(query_time_with_axis) + self.fc1(values)))\n","    #     # print(\"Query\", tf.reshape(query_time_with_axis, shape=(query_time_with_axis.shape[0], -1, )), self.fc1(values).shape)\n","    #     score = tf.matmul(query_time_with_axis, self.fc(values), transpose_b=True)\n","    #     # score = tf.expand_dims(score, axis=1)\n","    #     score = tf.squeeze(score, [1])\n","    #     # score = tf.transpose(score, [0, 2, 1])\n","    #     # print(\"Query\", score.shape)        \n","    #     # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","    #     attention_weights = tf.nn.softmax(score, axis=1)\n","    #     attention_weights = tf.expand_dims(attention_weights, axis=-1)\n","    #     # Point wise element multi (not dot product)\n","    #     # context_vector = tf.reduce_sum(attention_weights. * values, axis=1)\n","    #     context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n","    #     # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","\n","    #     return context_vector, attention_weights\n","\n","    def call(self, query, values, *args):\n","        \"\"\"\n","\n","        :param query: The hidden from encoder (batch_size, enc_hidden)\n","        :param values: encoder output (batch_size, seq_len, enc_hidden)\n","        :param args:\n","        :return:\n","        \"\"\"\n","\n","        # query hidden state shape == (batch_size, hidden size)\n","        # query_with_time_axis shape == (batch_size, 1, hidden size)\n","        # values shape == (batch_size, max_len, hidden size)\n","        # expand dim to broadcast addition along the time axis to calculate the score\n","        query_time_with_axis = tf.expand_dims(query, axis=1)\n","        # fc2 --> (batch_size, ..., units)\n","        # fc1 --> (batch_size, ..., units)\n","        # fc1 + fc2 --> (batch_size, ..., units)\n","        # V --> (batch_size, ..., 1) (score shape)\n","        # score = self.V(tf.tanh(self.fc2(query_time_with_axis) + self.fc1(values)))\n","        # print(\"Query\", tf.reshape(query_time_with_axis, shape=(query_time_with_axis.shape[0], -1, )), self.fc1(values).shape)\n","        score = tf.matmul(self.fc1(query_time_with_axis), self.fc2(values), transpose_b=True)\n","        # score = tf.expand_dims(score, axis=1)\n","        score = tf.transpose(score, [0, 2, 1])\n","        # print(\"Score shape\", score.shape)\n","        # score = tf.transpose(score, [0, 2, 1])\n","        # print(\"Query\", score.shape)        \n","        # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","        attention_weights = tf.nn.softmax(score, axis=-1)\n","        \n","        # Point wise element multi (not dot product)\n","        # context_vector = tf.reduce_sum(attention_weights. * values, axis=1)\n","        # print(\"Att\", attention_weights.shape, values.shape)\n","        # context_vector = tf.squeeze(tf.matmul(tf.expand_dims(attention_weights, axis=1), values), [1])\n","        context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n","        # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","\n","        return context_vector, attention_weights\n","\n","    # def call(self, inputs, training=None, mask=None):\n","    #     encoder_out, hidden = inputs\n","    #     score = self.V(tf.tanh(self.fc2(encoder_out) + self.fc1(hidden)))\n","    #     # attention_weights = tf.keras.layers.Softmax(axis=1)(score)\n","    #     attention_weights = tf.nn.softmax(score, axis=1)\n","    #     context_vector = tf.reduce_sum(attention_weights * encoder_out, axis=1)\n","    #     # context_vector = tf.reduce_sum(tf.matmul(attention_weights, encoder_out), axis=1)\n","    #\n","    #     return context_vector, attention_weights\n","\n","attention = LuongAttention(1024)\n","attention_context, attention_weights = attention(sample_hidden, sample_output)\n","\n","\"Attention context shape: \", attention_context.shape, \"attention weights shape: \", attention_weights.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Attention context shape: ',\n"," TensorShape([64, 1024]),\n"," 'attention weights shape: ',\n"," TensorShape([64, 15, 1]))"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"IOXqDioW0Ju9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957244278,"user_tz":-420,"elapsed":1616,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"ef5818ea-fdc8-4559-bfac-c99bb38e6fd0"},"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units):\n","        super(Decoder, self).__init__()\n","        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n","        self.gru = tf.keras.layers.GRU(units=dec_units, return_state=True, return_sequences=True,\n","                                       recurrent_initializer=\"glorot_uniform\")\n","\n","        self.final_fc = tf.keras.layers.Dense(vocab_size)\n","\n","        self.attention = LuongAttention(dec_units)\n","\n","    def call(self, x, hidden, enc_output):\n","        \"\"\"\n","        :param x: inputs\n","        :param hidden: hidden from encoder\n","        :param enc_output: output of encoder\n","        :return:\n","        \"\"\"\n","\n","        # (batch_size, hidden_units), (batch_size, seq_len, hidden_units)\n","        # embedded (batch_size, ..., embedding_dim)\n","        # concat (batch_size, ..., embedding_dim + units)\n","        # gru --> out (batch_size, ..., units), state (batch_size, units)\n","        # reshape --> merge batch_size and ... --> (batch_size, units)\n","        # fc --> (batch_size, vocab_size)\n","        context_vector, context_weights = self.attention(hidden, enc_output)\n","        x = self.embedding(x)\n","        x = tf.concat([x, tf.expand_dims(context_vector, axis=1)], axis=-1)\n","\n","        out, state = self.gru(x)\n","\n","        out = tf.reshape(out, shape=(-1, out.shape[2]))\n","\n","        x = self.final_fc(out)\n","\n","        return x, state, attention_weights\n","\n","\n","decoder = Decoder(vocab_tar_size, embedding_dim=EMBEDDING_DIM, dec_units=DEC_UNITS)\n","\n","sample_decode_output, _, _ = decoder(tf.random.uniform(shape=(BATCH_SIZE, 1)), sample_hidden, sample_output)\n","\n","sample_decode_output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 8952])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"RHyvfgwf0Ju-"},"source":["optimizer = tf.keras.optimizers.Adam()\n","sparse_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_func(real, pred):\n","    # Mask for target (0 is mask, 1 is real target)\n","    mask = tf.math.logical_not(tf.equal(real, 0))\n","    loss = sparse_loss(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    # ignore for mask loss\n","    loss *= mask\n","\n","    return tf.reduce_mean(loss)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYUl3V5p0Ju-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615957244281,"user_tz":-420,"elapsed":1597,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"a38a2a18-2431-473f-e351-18fb39ed8466"},"source":["encoder = Encoder(vocab_size=vocab_inp_size, embedding_dim=EMBEDDING_DIM, encoder_units=ENC_UNITS, batch_size=BATCH_SIZE)\n","decoder = Decoder(vocab_size=vocab_tar_size, embedding_dim=EMBEDDING_DIM, dec_units=DEC_UNITS)\n","\n","checkpoint_dir = \"/content/data/MyDrive/checkpoints/text_translate_multi\"\n","checkpoint = tf.train.Checkpoint(encoder=encoder, decoder=decoder, optimizer=optimizer, step=tf.Variable(1))\n","manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=1)\n","# checkpoint.restore(manager.latest_checkpoint)\n","# if manager.latest_checkpoint:\n","#     print(\"Restored from {}\".format(manager.latest_checkpoint))\n","# else:\n","#     print(\"Initializing from scratch.\")\n","\n","checkpoint"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.Checkpoint at 0x7f2e4a9ab290>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"06rDLtN_0Ju-"},"source":["@tf.function\n","def train_step(inp, tar, enc_hidden):\n","    \"\"\"\n","    Pass the input through the encoder which return encoder output and the encoder hidden state.\n","    The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.\n","    The decoder returns the predictions and the decoder hidden state.\n","    The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n","    Use teacher forcing to decide the next input to the decoder.\n","    Teacher forcing is the technique where the target word is passed as the next input to the decoder.\n","    The final step is to calculate the gradients and apply it to the optimizer and backpropagate\n","    :param inp:\n","    :param tar:\n","    :param enc_hidden:\n","    :return:\n","    \"\"\"\n","    loss = 0.0\n","\n","    with tf.GradientTape() as g:\n","\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","        dec_input = tf.expand_dims([tar_tokenizer.word_index['<start>']] * BATCH_SIZE, axis=1)\n","        dec_hidden = enc_hidden\n","        for t in range(1, tar.shape[1]):\n","            predictions, state, _ = decoder(dec_input, dec_hidden, enc_output)\n","            loss += loss_func(tar[:, t], predictions)\n","\n","            dec_input = tf.expand_dims(tar[:, t], axis=1)\n","\n","    batch_loss = (loss / int(tar.shape[1]))\n","\n","    train_variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","    gradients = g.gradient(loss, train_variables)\n","\n","    optimizer.apply_gradients(zip(gradients, train_variables))\n","\n","    return batch_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLf2pmJq0Ju_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1615958171903,"user_tz":-420,"elapsed":929197,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"4c925a41-7e1d-4d7f-87fd-a5c377dfe104"},"source":["EPOCHS = 20\n","steps_per_epoch = len(inp_tensor_train) // BATCH_SIZE\n","\n","for epoch in range(EPOCHS):\n","    total_loss = 0\n","    enc_hidden = encoder.initialize_hidden()\n","    start = time.time()\n","    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n","        loss = train_step(inp, tar, enc_hidden)\n","        total_loss += loss\n","\n","        if batch % 100 == 0:\n","            print('Epoch %d Batch %d Loss %.4f' % (epoch + 1, batch, loss.numpy()))\n","    \n","    \n","    # checkpoint.step.assign_add(1)\n","    # manager.save()\n","\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.7870\n","Epoch 1 Batch 100 Loss 2.0602\n","Epoch 1 Batch 200 Loss 1.8342\n","Epoch 1 Batch 300 Loss 1.5501\n","Epoch 1 Batch 400 Loss 1.5362\n","Epoch 1 Batch 500 Loss 1.3784\n","Epoch 1 Batch 600 Loss 1.1602\n","Epoch 1 Batch 700 Loss 1.1297\n","Epoch 1 Batch 800 Loss 0.9882\n","Epoch 1 Batch 900 Loss 1.0525\n","Epoch 1 Batch 1000 Loss 0.9373\n","Epoch 1 Batch 1100 Loss 0.8996\n","Epoch 1 Batch 1200 Loss 0.6643\n","Epoch 1 Batch 1300 Loss 0.8517\n","Epoch 1 Batch 1400 Loss 0.7225\n","Epoch 1 Batch 1500 Loss 0.6411\n","Epoch 1 Batch 1600 Loss 0.8605\n","Epoch 1 Batch 1700 Loss 0.7390\n","Epoch 1 Loss 1.1546\n","Time taken for 1 epoch 184.0418200492859 sec\n","\n","Epoch 2 Batch 0 Loss 0.5814\n","Epoch 2 Batch 100 Loss 0.5878\n","Epoch 2 Batch 200 Loss 0.6399\n","Epoch 2 Batch 300 Loss 0.5180\n","Epoch 2 Batch 400 Loss 0.5687\n","Epoch 2 Batch 500 Loss 0.5733\n","Epoch 2 Batch 600 Loss 0.4641\n","Epoch 2 Batch 700 Loss 0.5103\n","Epoch 2 Batch 800 Loss 0.3870\n","Epoch 2 Batch 900 Loss 0.4588\n","Epoch 2 Batch 1000 Loss 0.3946\n","Epoch 2 Batch 1100 Loss 0.4188\n","Epoch 2 Batch 1200 Loss 0.3449\n","Epoch 2 Batch 1300 Loss 0.4337\n","Epoch 2 Batch 1400 Loss 0.3903\n","Epoch 2 Batch 1500 Loss 0.3138\n","Epoch 2 Batch 1600 Loss 0.5093\n","Epoch 2 Batch 1700 Loss 0.3793\n","Epoch 2 Loss 0.4604\n","Time taken for 1 epoch 172.37586188316345 sec\n","\n","Epoch 3 Batch 0 Loss 0.2862\n","Epoch 3 Batch 100 Loss 0.2913\n","Epoch 3 Batch 200 Loss 0.3605\n","Epoch 3 Batch 300 Loss 0.3097\n","Epoch 3 Batch 400 Loss 0.3005\n","Epoch 3 Batch 500 Loss 0.3047\n","Epoch 3 Batch 600 Loss 0.3108\n","Epoch 3 Batch 700 Loss 0.3050\n","Epoch 3 Batch 800 Loss 0.2168\n","Epoch 3 Batch 900 Loss 0.2299\n","Epoch 3 Batch 1000 Loss 0.2026\n","Epoch 3 Batch 1100 Loss 0.2416\n","Epoch 3 Batch 1200 Loss 0.2359\n","Epoch 3 Batch 1300 Loss 0.2779\n","Epoch 3 Batch 1400 Loss 0.2646\n","Epoch 3 Batch 1500 Loss 0.2134\n","Epoch 3 Batch 1600 Loss 0.3307\n","Epoch 3 Batch 1700 Loss 0.2188\n","Epoch 3 Loss 0.2658\n","Time taken for 1 epoch 172.09218382835388 sec\n","\n","Epoch 4 Batch 0 Loss 0.2031\n","Epoch 4 Batch 100 Loss 0.2108\n","Epoch 4 Batch 200 Loss 0.2618\n","Epoch 4 Batch 300 Loss 0.1760\n","Epoch 4 Batch 400 Loss 0.2183\n","Epoch 4 Batch 500 Loss 0.2075\n","Epoch 4 Batch 600 Loss 0.2169\n","Epoch 4 Batch 700 Loss 0.2119\n","Epoch 4 Batch 800 Loss 0.1439\n","Epoch 4 Batch 900 Loss 0.1859\n","Epoch 4 Batch 1000 Loss 0.1403\n","Epoch 4 Batch 1100 Loss 0.1754\n","Epoch 4 Batch 1200 Loss 0.1856\n","Epoch 4 Batch 1300 Loss 0.1971\n","Epoch 4 Batch 1400 Loss 0.1793\n","Epoch 4 Batch 1500 Loss 0.1536\n","Epoch 4 Batch 1600 Loss 0.2396\n","Epoch 4 Batch 1700 Loss 0.1881\n","Epoch 4 Loss 0.1863\n","Time taken for 1 epoch 170.4773304462433 sec\n","\n","Epoch 5 Batch 0 Loss 0.1579\n","Epoch 5 Batch 100 Loss 0.1556\n","Epoch 5 Batch 200 Loss 0.2037\n","Epoch 5 Batch 300 Loss 0.1580\n","Epoch 5 Batch 400 Loss 0.1745\n","Epoch 5 Batch 500 Loss 0.1597\n","Epoch 5 Batch 600 Loss 0.1931\n","Epoch 5 Batch 700 Loss 0.1617\n","Epoch 5 Batch 800 Loss 0.1167\n","Epoch 5 Batch 900 Loss 0.1264\n","Epoch 5 Batch 1000 Loss 0.1132\n","Epoch 5 Batch 1100 Loss 0.1594\n","Epoch 5 Batch 1200 Loss 0.1629\n","Epoch 5 Batch 1300 Loss 0.1512\n","Epoch 5 Batch 1400 Loss 0.1639\n","Epoch 5 Batch 1500 Loss 0.1302\n","Epoch 5 Batch 1600 Loss 0.2005\n","Epoch 5 Batch 1700 Loss 0.1271\n","Epoch 5 Loss 0.1502\n","Time taken for 1 epoch 169.75670528411865 sec\n","\n","Epoch 6 Batch 0 Loss 0.1458\n","Epoch 6 Batch 100 Loss 0.1191\n","Epoch 6 Batch 200 Loss 0.1779\n","Epoch 6 Batch 300 Loss 0.1410\n","Epoch 6 Batch 400 Loss 0.1512\n","Epoch 6 Batch 500 Loss 0.0999\n","Epoch 6 Batch 600 Loss 0.1966\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-84010881ed6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"tRDqQUpf_6wN"},"source":["def evaluate(sentence):\n","    sentence = sentence.lower()\n","    attention_plot = np.zeros(shape=(max_len_tar, max_len_tar))\n","\n","    sentence = preprocess_word(sentence)\n","    inputs = [inp_tokenizer.word_index[word] for word in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_inp, padding=\"post\")\n","\n","    # print(\"inputs\", inputs)\n","\n","    result = ''\n","\n","    hidden = [tf.zeros(shape=(1, DEC_UNITS))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([tar_tokenizer.word_index['<start>']], axis=0)\n","\n","    for t in range(max_len_tar):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n","        # print(\"Predictions\", predictions[0].shape)\n","        attention_weights = tf.reshape(attention_weights, shape=(-1, ))\n","\n","        prediction_id = tf.argmax(predictions[0], axis=0).numpy()\n","        # print(\"Predict id\", prediction_id)\n","\n","        result += tar_tokenizer.index_word[prediction_id] + ' '\n","\n","        if tar_tokenizer.index_word[prediction_id] == '<end>':\n","            return result, sentence, attention_plot\n","        \n","        dec_input = tf.expand_dims([prediction_id], axis=0)\n","    \n","    return result, sentence, attention_plot\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qD1OK6AnEsGG"},"source":["def translate(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","\n","    print('Input: %s' % sentence)\n","    print(\"Predicted translation: {}\".format(result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6oky5zObEw_y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615958304125,"user_tz":-420,"elapsed":1568,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"}},"outputId":"1891dffa-82f2-4fa5-e285-8ba66df1dc91"},"source":["translate(u'Я не могу найти свой телефон.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Input: <start> я не могу найти свой телефон . <end>\n","Predicted translation: i can't find my wallet . <end> \n"],"name":"stdout"}]}]}