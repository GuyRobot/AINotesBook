{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"6yXAu_xCq77p"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3199,"status":"ok","timestamp":1612167521148,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"952rD388q77u","outputId":"528330ef-2100-456a-cf2d-5be76a911165"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2646016/2638744 [==============================] - 0s 0us/step\n"]}],"source":["path_to_download = tf.keras.utils.get_file(\n","    'spa-eng.zip',\n","    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True\n",")\n","\n","path_to_file = os.path.join(os.path.dirname(path_to_download), 'spa-eng', 'spa.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2fqQxBzq77v"},"outputs":[],"source":["def unicode_to_ascii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                   if unicodedata.category(c) != 'Mn')\n","\n","\n","def preprocess_sentences(w):\n","    w = unicode_to_ascii(w.lower().strip())\n","\n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a bout.\" =\u003e \"he is a boy .\"\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","\n","    # replacing everything with space except alphabet, ., ?, !, ,\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", ' ', w)\n","\n","    w = w.strip()\n","\n","    # adding end and start token to sentence to know when to start and stop predict\n","    w = '\u003cstart\u003e %s \u003cend\u003e' % w\n","    return w\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3189,"status":"ok","timestamp":1612167521149,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"_cdzJh8Xq77v","outputId":"a804612a-c5f6-45dc-b100-50e7a9f9662b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cstart\u003e may i borrow this book ? \u003cend\u003e\n","b'\u003cstart\u003e \\xc2\\xbf puedo tomar prestado este libro ? \u003cend\u003e'\n"]}],"source":["en_sentence = u\"May I borrow this book?\"\n","sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n","\n","print(preprocess_sentences(en_sentence))\n","print(preprocess_sentences(sp_sentence).encode('utf-8'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7317,"status":"ok","timestamp":1612167525284,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"mfqMXkYXq77w","outputId":"7af5b567-8a42-40ea-acd4-6972d98aa355"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cstart\u003e if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . \u003cend\u003e\n","\u003cstart\u003e si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . \u003cend\u003e\n"]}],"source":["def create_dataset(path, num_examples):\n","    \"\"\"\n","    Remove the accents\n","    Clean the sentences\n","    Return word pairs in the format: [en, sp]\n","    :param path:\n","    :param num_examples:\n","    :return:\n","    \"\"\"\n","    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","    word_pairs = [[preprocess_sentences(word) for word in line.split('\\t')] for line in lines[:num_examples]]\n","    return zip(*word_pairs)\n","\n","en, sp = create_dataset(path_to_file, None)\n","print(en[-1])\n","print(sp[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bPTX9z8yq77w"},"outputs":[],"source":["def tokenize(lang):\n","    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","    lang_tokenizer.fit_on_texts(lang)\n","\n","    tensor = lang_tokenizer.texts_to_sequences(lang)\n","    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n","\n","    return tensor, lang_tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LF0Q51u7q77x"},"outputs":[],"source":["def load_dataset(path, num_examples=None):\n","    \"\"\"\n","    Creating cleaned input, output pairs\n","    :param path:\n","    :param num_examples:\n","    :return: input, target tensor and tokenize\n","    \"\"\"\n","    target_lang, input_lang = create_dataset(path, num_examples)\n","    input_tensor, input_lang_tokenizer = tokenize(input_lang)\n","    target_tensor, target_lang_tokenizer = tokenize(target_lang)\n","\n","    return input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HIReRse7q77x"},"outputs":[],"source":["# Fast Vs Good\n","num_examples = 30000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","\n","max_len_target, max_len_input = target_tensor.shape[1], input_tensor.shape[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10157,"status":"ok","timestamp":1612167528141,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"4-nmWD59q77x"},"outputs":[{"name":"stdout","output_type":"stream","text":["24000 24000 6000 6000\n"]}],"source":["# Train and validation set\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor,\n","                                                                                                target_tensor,\n","                                                                                                test_size=.2)\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6Vxk0Qugq77x"},"outputs":[],"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index) + 1\n","vocab_tar_size = len(targ_lang.word_index) + 1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14801,"status":"ok","timestamp":1612167532793,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"rO-2utRlq77y"},"outputs":[{"data":{"text/plain":["(TensorShape([64, 16]), TensorShape([64, 11]))"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19867,"status":"ok","timestamp":1612167537864,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"bVbBVraPq77y"},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}],"source":["# Encoder and Decoder\n","# The input is put through an encoder model which give the encoder output of shape\n","# (batch_size, max_length, hidden_size) and the encoder hidden state of shape (batch_size, hidden_size)\n","# a_ts = exp(score(ht,hs)) /  sum(exp(score(ht,hs)) Attention weights\n","# ct = sum(a_ts * hs)               Context vector\n","# at = f(ct, ht) = tanh(Wc[ct;ht])  Attention vector\n","# score(ht, hs) = ht.T*W*h_s or v_a.T * tanh(W1*ht + W2*h2))\n","\n","# score = FC(tanh(FC(EO) + FC(H))) (EO: encoder output)\n","# attention weights = softmax(score, axis=1) (axis 1 is max_length of input)\n","# context vector = sum(attention weights * EO, axis=1)\n","# embedding_output = the input to the decoder X is passed through an embedding layer\n","# merged vector = concat(embedding output, context vector)\n","# then feed to GRU\n","\n","class Encoder(tf.keras.Model):\n","    def get_config(self):\n","        pass\n","\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n","        super(Encoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.enc_units = enc_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                       return_sequences=True,\n","                                       return_state=True,\n","                                       recurrent_initializer='glorot_uniform')\n","\n","    def call(self, x, hidden=None, *args):\n","        x = self.embedding(x)\n","        output, state = self.gru(x, initial_state=hidden)\n","        return output, state\n","\n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_size, self.enc_units))\n","\n","\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21310,"status":"ok","timestamp":1612167539312,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"2_RsLQ7Sq77y"},"outputs":[{"name":"stdout","output_type":"stream","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"]}],"source":["class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super(BahdanauAttention, self).__init__()\n","        self.W1 = tf.keras.layers.Dense(units)\n","        self.W2 = tf.keras.layers.Dense(units)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","    def call(self, query, values=None, *args, **kwargs):\n","        \"\"\"\n","        query hidden state shape == (batch_size, hidden size)\n","        query_with_times_axis shape == (batch_size, 1, hidden_size)\n","        # values shape = (batch_size, max_len, hidden_size)\n","        broadcast addition along the time axis to calculate the score\n","        :param query:\n","        :param values:\n","        :param args:\n","        :param kwargs:\n","        :return:\n","        \"\"\"\n","        query_with_time_axis = tf.expand_dims(query, 1)\n","\n","        # score shape = (batch_size, max_length, 1)\n","        # get a at the last axis because we are applying score to self.V\n","        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n","\n","        # attention_weights shape == (batch_size, max_length, 1)\n","        attention_weights = tf.nn.softmax(score, axis=1)\n","\n","        # context_vector shape after sum == (batch_size, hidden_size)\n","        context_vector = attention_weights * values\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector, attention_weights\n","\n","\n","attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21307,"status":"ok","timestamp":1612167539313,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"dKUGKNqGq77z"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (64, 4935)\n"]}],"source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, decode_units, batch_size):\n","        super(Decoder, self).__init__()\n","        self.batch_size = batch_size\n","        self.decode_units = decode_units\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = tf.keras.layers.GRU(self.decode_units,\n","                                       return_sequences=True,\n","                                       return_state=True,\n","                                       recurrent_initializer='glorot_uniform')\n","        self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","        self.attention = BahdanauAttention(self.decode_units)\n","\n","    def call(self, x, hidden=None, enc_output=None, *args, **kwargs):\n","        # enc_output shape == (batch_size, max_length, hidden_size)\n","        context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","        x = self.embedding(x)\n","\n","        # x shape after concatenation = (batch_size, 1, embedding_dim + hidden_size)\n","        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","        # passing the concatenated vector to the GRU\n","        output, state = self.gru(x)\n","\n","        # output shape == (batch_size * 1, hidden_size)\n","        output = tf.reshape(output, shape=(-1, output.shape[2]))\n","\n","        # output shape == (batch_size, vocab)\n","        x = self.fc(output)\n","\n","        return x, state, attention_weights\n","\n","\n","decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"LMiKgnnfq77z"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_func(target, predict):\n","    mask = tf.math.logical_not(tf.math.equal(target, 0))\n","    loss_ = loss_object(target, predict)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_mean(loss_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wkHP3PQqq770"},"outputs":[],"source":["checkpoint_dir = './machine_translate_seq2seq_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lRREoVVSq770"},"outputs":[],"source":["# Training\n","# Pass the input through the encoder which return encoder output and the encoder hidden state\n","# The encoder output, encoder hidden state and the decoder input is passed to the decoder\n","# The decoder return the predictions and the decoder hidden state\n","# The decoder hidden state is then passed back into the model and the predictions\n","# are used to calculate the loss\n","# Use target word passed as the next input to the decoder to decide the next input to the decoder\n","# Then calculate the gradients and apply into optimizer and backpropagate\n","\n","@tf.function\n","def train_step(inp, target, enc_hidden):\n","    loss = 0\n","\n","    with tf.GradientTape() as g:\n","        enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","        dec_hidden = enc_hidden\n","\n","        dec_input = tf.expand_dims([targ_lang.word_index['\u003cstart\u003e']] * BATCH_SIZE, 1)\n","\n","        # Teacher forcing - feeding the target as the next input\n","        for t in range(1, target.shape[1]):\n","            # Pass enc_output to decoder\n","            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","            loss += loss_func(target[:, t], predictions)\n","\n","            dec_input = tf.expand_dims(target[:, t], 1)\n","\n","    batch_loss = (loss / int(target.shape[1]))\n","\n","    variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","    gradients = g.gradient(loss, variables)\n","\n","    optimizer.apply_gradients(zip(gradients, variables))\n","\n","    return batch_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362019,"status":"ok","timestamp":1612167880031,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"4ZorTG66q771","outputId":"5af4aa6f-25ff-40cf-bf27-c74437e007d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.6266\n","Epoch 1 Batch 100 Loss 2.1336\n","Epoch 1 Batch 200 Loss 1.9243\n","Epoch 1 Batch 300 Loss 1.8248\n","Epoch 1 Loss 2.0274\n","Time taken for 1 epoch 44.048670291900635 sec\n","\n","Epoch 2 Batch 0 Loss 1.4617\n","Epoch 2 Batch 100 Loss 1.5378\n","Epoch 2 Batch 200 Loss 1.3653\n","Epoch 2 Batch 300 Loss 1.2314\n","Epoch 2 Loss 1.3833\n","Time taken for 1 epoch 33.297605991363525 sec\n","\n","Epoch 3 Batch 0 Loss 1.0757\n","Epoch 3 Batch 100 Loss 1.0249\n","Epoch 3 Batch 200 Loss 1.0006\n","Epoch 3 Batch 300 Loss 0.8782\n","Epoch 3 Loss 0.9453\n","Time taken for 1 epoch 32.94306707382202 sec\n","\n","Epoch 4 Batch 0 Loss 0.7620\n","Epoch 4 Batch 100 Loss 0.6685\n","Epoch 4 Batch 200 Loss 0.5902\n","Epoch 4 Batch 300 Loss 0.5069\n","Epoch 4 Loss 0.6294\n","Time taken for 1 epoch 32.927040338516235 sec\n","\n","Epoch 5 Batch 0 Loss 0.3975\n","Epoch 5 Batch 100 Loss 0.3829\n","Epoch 5 Batch 200 Loss 0.3912\n","Epoch 5 Batch 300 Loss 0.4713\n","Epoch 5 Loss 0.4269\n","Time taken for 1 epoch 33.457534313201904 sec\n","\n","Epoch 6 Batch 0 Loss 0.2650\n","Epoch 6 Batch 100 Loss 0.3187\n","Epoch 6 Batch 200 Loss 0.2761\n","Epoch 6 Batch 300 Loss 0.2606\n","Epoch 6 Loss 0.2928\n","Time taken for 1 epoch 32.62968730926514 sec\n","\n","Epoch 7 Batch 0 Loss 0.1942\n","Epoch 7 Batch 100 Loss 0.1998\n","Epoch 7 Batch 200 Loss 0.1932\n","Epoch 7 Batch 300 Loss 0.1815\n","Epoch 7 Loss 0.2102\n","Time taken for 1 epoch 32.48503279685974 sec\n","\n","Epoch 8 Batch 0 Loss 0.1454\n","Epoch 8 Batch 100 Loss 0.1638\n","Epoch 8 Batch 200 Loss 0.1513\n","Epoch 8 Batch 300 Loss 0.2199\n","Epoch 8 Loss 0.1573\n","Time taken for 1 epoch 32.72608137130737 sec\n","\n","Epoch 9 Batch 0 Loss 0.1064\n","Epoch 9 Batch 100 Loss 0.0949\n","Epoch 9 Batch 200 Loss 0.1215\n","Epoch 9 Batch 300 Loss 0.1799\n","Epoch 9 Loss 0.1214\n","Time taken for 1 epoch 32.823272943496704 sec\n","\n","Epoch 10 Batch 0 Loss 0.1037\n","Epoch 10 Batch 100 Loss 0.0872\n","Epoch 10 Batch 200 Loss 0.1277\n","Epoch 10 Batch 300 Loss 0.1198\n","Epoch 10 Loss 0.0995\n","Time taken for 1 epoch 33.258915424346924 sec\n","\n"]}],"source":["EPOCHS = 20\n","\n","for epoch in range(EPOCHS):\n","    start = time.time()\n","\n","    enc_hidden = encoder.initialize_hidden_state()\n","    total_loss = 0\n","\n","    for (batch, (inp, target)) in enumerate(dataset.take(steps_per_epoch)):\n","        batch_loss = train_step(inp, target, enc_hidden)\n","        total_loss += batch_loss\n","\n","        if batch % 100 == 0:\n","            print('Epoch %d Batch %d Loss %.4f' % (epoch + 1, batch, batch_loss.numpy()))\n","\n","\n","    if (epoch + 1) % 5 == 0:\n","        checkpoint.save(file_prefix=checkpoint_prefix)\n","\n","    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsvYdQspq771"},"outputs":[],"source":["# Translate\n","# The input to the decoder at each time step is its previous predictions along with the hidden state and\n","# the decoder output\n","# Stop prediction when reach end token and store the attention weights for every time step\n","# The encoder output is calculated only once for one input\n","\n","def evaluate(sentence):\n","    attention_plot = np.zeros((max_len_target, max_len_input))\n","\n","    sentence = preprocess_sentences(sentence)\n","\n","    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_len_input, padding='post')\n","\n","    inputs = tf.convert_to_tensor(inputs)\n","\n","    result = ''\n","\n","    hidden = [tf.zeros((1, units))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['\u003cstart\u003e']], 0)\n","\n","    for t in range(max_len_target):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n","\n","        # Storing the attention weights to plot later on\n","        attention_weights = tf.reshape(attention_weights, shape=(-1, ))\n","        attention_plot[t] = attention_weights.numpy()\n","\n","        prediction_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += targ_lang.index_word[prediction_id] + ' '\n","\n","        if targ_lang.index_word[prediction_id] == '\u003cend\u003e':\n","            return result, sentence, attention_plot\n","\n","        # Feed back into the model the predicted id\n","        dec_input = tf.expand_dims([prediction_id], 0)\n","\n","    return result, sentence, attention_plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kn3-rA1xq771"},"outputs":[],"source":["def plot_attention(attention, sentence, predicted_sentence):\n","    fig = plt.figure(figsize=(10, 10))\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.matshow(attention, cmap='viridis')\n","\n","    ax.set_xticklabels([''] + sentence, rotation=90)\n","    ax.set_yticklabels([''] + predicted_sentence)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WC4Gzl5dq771"},"outputs":[],"source":["def translate(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","\n","    print('Input: %s' % sentence)\n","    print(\"Predicted translation: {}\".format(result))\n","\n","    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"executionInfo":{"elapsed":992,"status":"ok","timestamp":1612168428137,"user":{"displayName":"Guys Users","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPDLTE2xq9CHYxzYfOVoXbFT7HwhIJa5bkbk16=s64","userId":"03786715776420508747"},"user_tz":-420},"id":"FaFz2tKOq772","outputId":"1f47e567-36c9-40ac-cbdd-1af9f2b138df"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: \u003cstart\u003e hace mucho frio aqui . \u003cend\u003e\n","Predicted translation: it s very cold here . \u003cend\u003e \n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 720x720 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","translate(u'hace mucho frio aqui.')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"MachineTranslateWithAttentionSeq2Seq.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"}},"nbformat":4,"nbformat_minor":0}